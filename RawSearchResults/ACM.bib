@inproceedings{10.1145/2804360.2804364,
author = {Granli, William and Burchell, John and Hammouda, Imed and Knauss, Eric},
title = {The Driving Forces of API Evolution},
year = {2015},
isbn = {9781450338165},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/2804360.2804364},
doi = {10.1145/2804360.2804364},
abstract = { Evolving an Application Programming Interface (API) is a delicate activity, as modifications to them can significantly impact their users. The increasing use of APIs means that software development organisations must take an empirical and scientific approach to the way they manage the evolution of their APIs. If no attempt at analysing or quantifying the evolution of an API is made, there will be a diminished understanding of the evolution, and possible improvements to the maintenance strategy will be difficult to identify. We believe that long-standing software evolution theories can provide additional insight to the field of APIs, and can be of great use to companies maintaining APIs. In this case study, we conduct a qualitative investigation to understand what drives the evolution of an industry company's existing API, by examining two versions of the API interface. The changes were analysed based on two software evolution theories, and the extent to which we could reverse engineer the change decisions was determined by interviewing an architect of the API. The results of this analysis show that the largest driving force of the APIs evolution was the desire for new functionality. Our findings which show that changes happen sporadically, rather than continuously, appear to show that the law of Conservation of Organisational Stability was not a considerable factor for the evolution of the API. We also found that it is possible to reverse engineer change decisions and in doing so, identified that the feedback loop of an API is an important area of improvement. },
booktitle = {Proceedings of the 14th International Workshop on Principles of Software Evolution},
pages = {28–37},
numpages = {10},
keywords = {Software Maintenance, API Design, Software Evolution},
location = {Bergamo, Italy},
series = {IWPSE 2015}
}

@inproceedings{10.1145/1108792.1108818,
author = {Perkins, Jeff H.},
title = {Automatically Generating Refactorings to Support API Evolution},
year = {2005},
isbn = {1595932399},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/1108792.1108818},
doi = {10.1145/1108792.1108818},
abstract = {When library APIs change, client code should change in response, in order to avoid erroneous behavior, compilation failures, or warnings. Previous research has introduced techniques for generating such client refactorings. This paper improves on the previous work by proposing a novel, lightweight technique that takes advantage of information that programmers can insert in the code rather than forcing them to use a different tool to re-express it. The key idea is to replace calls to deprecated methods by their bodies, where those bodies consist of the appropriate replacement code. This approach has several benefits. It requires no change in library development practice, since programmers already adjust method bodies and/or write example code, and there are no new tools or languages to learn. It does not require distribution of new artifacts, and a tool to apply it can be lightweight. We evaluated the applicability of our approach on a number of libraries and found it to to be applicable in more than 75% of the cases.},
booktitle = {Proceedings of the 6th ACM SIGPLAN-SIGSOFT Workshop on Program Analysis for Software Tools and Engineering},
pages = {111–114},
numpages = {4},
location = {Lisbon, Portugal},
series = {PASTE '05}
}

@article{10.1145/1108768.1108818,
author = {Perkins, Jeff H.},
title = {Automatically Generating Refactorings to Support API Evolution},
year = {2005},
issue_date = {January 2006},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {1},
issn = {0163-5948},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/1108768.1108818},
doi = {10.1145/1108768.1108818},
abstract = {When library APIs change, client code should change in response, in order to avoid erroneous behavior, compilation failures, or warnings. Previous research has introduced techniques for generating such client refactorings. This paper improves on the previous work by proposing a novel, lightweight technique that takes advantage of information that programmers can insert in the code rather than forcing them to use a different tool to re-express it. The key idea is to replace calls to deprecated methods by their bodies, where those bodies consist of the appropriate replacement code. This approach has several benefits. It requires no change in library development practice, since programmers already adjust method bodies and/or write example code, and there are no new tools or languages to learn. It does not require distribution of new artifacts, and a tool to apply it can be lightweight. We evaluated the applicability of our approach on a number of libraries and found it to to be applicable in more than 75% of the cases.},
journal = {SIGSOFT Softw. Eng. Notes},
month = sep,
pages = {111–114},
numpages = {4}
}

@inproceedings{10.1109/ICSE.2009.5070565,
author = {Dagenais, Barthelemy and Robillard, Martin P.},
title = {SemDiff: Analysis and Recommendation Support for API Evolution},
year = {2009},
isbn = {9781424434534},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1109/ICSE.2009.5070565},
doi = {10.1109/ICSE.2009.5070565},
abstract = {As a framework evolves, changes in its Application Programming Interface (API) can break client programs that extend the framework. Repairing a client program can be a challenging task because developers need to understand the context surrounding the API change. This paper describes SemDiff, a tool that recommends replacements for framework methods that were accessed by a client program and deleted during the evolution of the framework. SemDiff recommends replacements for non-trivial changes undiscovered by other change-detection techniques and also enables developers to look at the context of the changes that led to the deletion of a framework method.},
booktitle = {Proceedings of the 31st International Conference on Software Engineering},
pages = {599–602},
numpages = {4},
series = {ICSE '09}
}

@inproceedings{10.1145/1062455.1062512,
author = {Henkel, Johannes and Diwan, Amer},
title = {CatchUp! Capturing and Replaying Refactorings to Support API Evolution},
year = {2005},
isbn = {1581139632},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/1062455.1062512},
doi = {10.1145/1062455.1062512},
abstract = {Library developers who have to evolve a library to accommodate changing requirements often face a dilemma: Either they implement a clean, efficient solution but risk breaking client code, or they maintain compatibility with client code, but pay with increased design complexity and thus higher maintenance costs over time.We address this dilemma by presenting a lightweight approach for evolving application programming interfaces (APIs), which does not depend on version control or configuration management systems. Instead, we capture API refactoring actions as a developer evolves an API. Users of the API can then replay the refactorings to bring their client software components up to date.We present catchup!, an implementation of our approach that captures and replays refactoring actions within an integrated development environment semi-automatically. Our experiments suggest that our approach could be valuable in practice.},
booktitle = {Proceedings of the 27th International Conference on Software Engineering},
pages = {274–283},
numpages = {10},
keywords = {refactoring, software evolution, application programming interfaces},
location = {St. Louis, MO, USA},
series = {ICSE '05}
}

@inproceedings{10.1145/2508075.2508094,
author = {H\'{y}bl, Jan and Tron\'{\i}\v{c}ek, Zden\v{e}k},
title = {On Testing the Source Compatibility in Java},
year = {2013},
isbn = {9781450319959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/2508075.2508094},
doi = {10.1145/2508075.2508094},
abstract = {When software components evolve, they change interfaces, which may break backward compatibility. We present a tool that facilitates checking whether a new version of component is source compatible with a previous version. This tool figures out the component interface and generates the client code that uses the component interface to maximum extent. If the generated client compiles against the new component interface, those two versions are more or less compatible. The tool can be useful for API authors.},
booktitle = {Proceedings of the 2013 Companion Publication for Conference on Systems, Programming, &amp; Applications: Software for Humanity},
pages = {87–88},
numpages = {2},
keywords = {software evolution, API evolution, Java, source compatibility},
location = {Indianapolis, Indiana, USA},
series = {SPLASH '13}
}

@inproceedings{10.1145/2245276.2231959,
author = {Tron\'{\i}\v{c}ek, Zden\v{e}k},
title = {RefactoringNG: A Flexible Java Refactoring Tool},
year = {2012},
isbn = {9781450308571},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/2245276.2231959},
doi = {10.1145/2245276.2231959},
abstract = {The Java programming language and the Java API evolve and this evolution certainly will continue in future. Upgrade to a new version of programming language or API is nowadays usually done manually. We describe a new flexible refactoring tool for the Java programming language that can upgrade the code almost automatically. The tool performs refactoring rules described in the special language based on the abstract syntax trees. Each rule consists of two abstract syntax trees: the pattern and the rewrite. First, we search for the pattern and then replace each pattern occurrence with the rewrite. Searching and replacement is performed on the abstract syntax trees that are built and fully attributed by the Java compiler. Complete syntactic and semantic information about the source code and flexibility in refactoring rules give the tool competitive advantage over most similar tools.},
booktitle = {Proceedings of the 27th Annual ACM Symposium on Applied Computing},
pages = {1165–1170},
numpages = {6},
keywords = {API evolution, Java, refactoring, software evolution},
location = {Trento, Italy},
series = {SAC '12}
}

@inproceedings{10.1145/3377811.3380357,
author = {Xia, Hao and Zhang, Yuan and Zhou, Yingtian and Chen, Xiaoting and Wang, Yang and Zhang, Xiangyu and Cui, Shuaishuai and Hong, Geng and Zhang, Xiaohan and Yang, Min and Yang, Zhemin},
title = {How Android Developers Handle Evolution-Induced API Compatibility Issues: A Large-Scale Study},
year = {2020},
isbn = {9781450371216},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/3377811.3380357},
doi = {10.1145/3377811.3380357},
abstract = {As Android platform evolves in a fast pace, API-related compatibility issues become a significant challenge for developers. To handle an incompatible API invocation, developers mainly have two choices: merely performing sufficient checks to avoid invoking incompatible APIs on platforms that do not support them, or gracefully providing replacement implementations on those incompatible platforms. As providing more consistent app behaviors, the latter one is more recommended and more challenging to adopt. However, it is still unknown how these issues are handled in the real world, do developers meet difficulties and what can we do to help them.In light of this, this paper performs the first large-scale study on the current practice of handling evolution-induced API compatibility issues in about 300,000 Android market apps, and more importantly, their solutions (if exist). Actually, it is in general very challenging to determine if developers have put in counter-measure for a compatibility issue, as different APIs have diverse behaviors, rendering various repair. To facilitate a large-scale study, this paper proposes RAPID, an automated tool to determine whether a compatibility issue has been addressed or not, by incorporating both static analysis and machine learning techniques. Results show that our trained classifier is quite effective by achieving a F1-score of 95.21% and 91.96% in the training stage and the validation stage respectively. With the help of RAPID, our study yields many interesting findings, e.g. developers are not willing to provide alternative implementations when handling incompatible API invocations (only 38.4%); for those incompatible APIs that Google gives replacement recommendations, the ratio of providing alternative implementations is significantly higher than those without recommendations; developers find more ways to repair compatibility issues than Google's recommendations and the knowledge acquired from these experienced developers would be extremely useful to novice developers and may significantly improve the current status of compatibility issue handling.},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering},
pages = {886–898},
numpages = {13},
keywords = {compatibility issues, API evolution, Android app analysis},
location = {Seoul, South Korea},
series = {ICSE '20}
}

@inproceedings{10.1145/3180155.3182518,
author = {Bagherzadeh, Mojtaba and Kahani, Nafiseh and Bezemer, Cor-Paul and Hassan, Ahmed E. and Dingel, Juergen and Cordy, James R.},
title = {Analyzing a Decade of Linux System Calls},
year = {2018},
isbn = {9781450356381},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/3180155.3182518},
doi = {10.1145/3180155.3182518},
abstract = {The Linux kernel provides its services to the application layer using so-called system calls. All system calls combined form the Application Programming Interface (API) of the kernel. Hence, system calls provide us with a window into the development process and design decisions that are made for the Linux kernel. Our paper [1] presents the result of an empirical study of the changes (8,770) that were made to the system calls during the last decade (i.e., from April 2005 to December 2014). The main contributions and most important findings of our study are:(1) An overview of the Linux system calls. As of December 2014, 396 system calls existed in the Linux kernel. They can be categorized into 10 groups (process management, signal processing, and so on). 76 of the system calls were added over the last decade (new system calls). A new system call is usually not activated for all architectures at the same time. 40 out of 76 (53%) new system calls and 102 of the 393 (26%) existing system calls were sibling calls. A sibling call is a system call that is similar in functionality, and often in name, to another system call.(2) A study of the evolution of the Linux system calls over the last decade in terms of the size and type of changes that were made to the system calls. With an average growth of 25 LOC per day, the Linux system calls are relatively stable. The commits that are made to system calls are slightly more scattered than kernel commits. There exists a small group of very active system call developers. 8,288 of the 8,770 studied commits (95%) were made to maintain, improve and fix bugs in system calls. 36% of the system call-related commits were bug fixes. 4,498 (50%) of the commits were made to only 25 (6%) of the 393 system calls. 35% of the system call-related commits were made to conduct code restructuring, and 36% of the system call-related commits were made to fix bugs.(3) A study of the type of bug fixes that were made to the system calls over the last decade. Developers make mistakes in the seemingly trivial activation process of a system call. The steps that are required to activate a system call, such as assigning the unique number and updating the system call table, are performed manually. 58% of the bug fix commits were made to fix semantic bugs. The proportion of bug fixes that fixed memory-related bugs remained constant throughout the last decade.(4) An analysis of the results and a discussion of their implications.Generalizability of results. We compared Linux system calls with FreeBSD system calls, to validate that our results are generalizable to other UNIX-based operating systems. Our findings for the FreeBSD operating system confirm that other UNIX-based operating systems use a system call mechanism that is similar to that of Linux. Therefore, we can safely assume that our findings are of value to other UNIX-based operating systems.Suggestion for automation. First, we suggest the automation of simple, reoccurring tasks in Linux, such as adding and removing system calls. Our study on FreeBSD shows that such tasks can successfully be automated. Second, we suggest that historical information about the evolution of a kernel API should be used to guide the testing process. Finally, we suggest that existing automated testing tools are extended to support testing system calls.Maintenance Effort. Compared to regular software systems, kernel APIs require an additional type of maintenance that involves adding and removing system calls. Also, approximately 11% of the maintenance effort of a kernel API is assigned to the infrastructure for providing the API.Overall, the results of our study can be beneficial to practitioners, researchers, and more specifically kernel developers, by providing insights related to the challenges and problems that come with long term maintenance of a kernel API, such as the long-lived Linux kernel API. We have published our classification of 8,870 system call-related changes [1] so that it can be used to conduct further studies.The full paper is accepted for publication in the Empirical Software Engineering journal, and can be found at: https://link-springer-com.proxy.lib.uwaterloo.ca/article/10.1007/s10664-017-9551-z.},
booktitle = {Proceedings of the 40th International Conference on Software Engineering},
pages = {267},
numpages = {1},
keywords = {software evolution, linux kernel, API evolution, system calls},
location = {Gothenburg, Sweden},
series = {ICSE '18}
}

@inproceedings{10.5555/3106050.3106056,
author = {Campinhos, Jo\~{a}o and Seco, Jo\~{a}o Costa and Cunha, J\'{a}come},
title = {Type-Safe Evolution of Web Services},
year = {2017},
isbn = {9781538628034},
publisher = {IEEE Press},
abstract = {Applications based on micro or web services have had significant growth due to the exponential increase in the use of mobile devices. However, using such kind of loosely coupled interfaces provides almost no guarantees to the developer in terms of evolution. Changes to service interfaces can be introduced at any moment, which may cause the system to fail due to mismatches between communicating parts.In this paper, we present a programming model that allows the development of web service applications, server end-points and their clients, in such a way that the evolution of services' implementation does not cause the disruption of the client. Our approach is based on a type based code slicing technique that ensures that each version only refers to type compatible code, of the same version or of a compatible version, and that each client request is redirected to the most recent type compatible version implemented by the server.We abstract the notion of version and parametrize type compatibility on the relation between versions. The relation between versions is tagged with compatibility levels, so to capture the common conventions used in software development. Our implementation allows multiple versions of a service to be deployed simultaneously, while reusing code between versions in a type safe way. We describe a prototype framework, based on code transformation, for server-side JavaScript code, and using Flow as verification tool.},
booktitle = {Proceedings of the 2nd International Workshop on Variability and Complexity in Software Design},
pages = {20–26},
numpages = {7},
keywords = {JavaScript, type safe, API evolution, web services},
location = {Buenos Aires, Argentina},
series = {VACE '17}
}

@inproceedings{10.1145/3194793.3194799,
author = {Eilertsen, Anna Maria and Bagge, Anya Helene},
title = {Exploring API: Client Co-Evolution},
year = {2018},
isbn = {9781450357548},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/3194793.3194799},
doi = {10.1145/3194793.3194799},
abstract = {Software libraries evolve over time, as do their APIs and the clients that use them. Studying this co-evolution of APIs and API clients can give useful insights into both how to manage the co-evolution, and how to design software so that it is more resilient against API changes.In this paper, we discuss problems and challenges of API and client code co-evolution, and the tools and methods we will need to resolve them.},
booktitle = {Proceedings of the 2nd International Workshop on API Usage and Evolution},
pages = {10–13},
numpages = {4},
keywords = {co-evolution, bytecode analysis, repository mining, software evolution, API evolution},
location = {Gothenburg, Sweden},
series = {WAPI '18}
}

@inproceedings{10.1145/1869459.1869486,
author = {Nguyen, Hoan Anh and Nguyen, Tung Thanh and Wilson, Gary and Nguyen, Anh Tuan and Kim, Miryung and Nguyen, Tien N.},
title = {A Graph-Based Approach to API Usage Adaptation},
year = {2010},
isbn = {9781450302036},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/1869459.1869486},
doi = {10.1145/1869459.1869486},
abstract = {Reusing existing library components is essential for reducing the cost of software development and maintenance. When library components evolve to accommodate new feature requests, to fix bugs, or to meet new standards, the clients of software libraries often need to make corresponding changes to correctly use the updated libraries. Existing API usage adaptation techniques support simple adaptation such as replacing the target of calls to a deprecated API, however, cannot handle complex adaptations such as creating a new object to be passed to a different API method, or adding an exception handling logic that surrounds the updated API method calls.This paper presents LIBSYNC that guides developers in adapting API usage code by learning complex API usage adaptation patterns from other clients that already migrated to a new library version (and also from the API usages within the library's test code). LIBSYNC uses several graph-based techniques (1) to identify changes to API declarations by comparing two library versions, (2) to extract associated API usage skeletons before and after library migration, and (3) to compare the extracted API usage skeletons to recover API usage adaptation patterns. Using the learned adaptation patterns, LIBSYNC recommends the locations and edit operations for adapting API usages. The evaluation of LIBSYNC on real-world software systems shows that it is highly correct and useful with a precision of 100% and a recall of 91%.},
booktitle = {Proceedings of the ACM International Conference on Object Oriented Programming Systems Languages and Applications},
pages = {302–321},
numpages = {20},
keywords = {API usage model, API usage adaptation, software evolution, API evolution, program differencing},
location = {Reno/Tahoe, Nevada, USA},
series = {OOPSLA '10}
}

@article{10.1145/1932682.1869486,
author = {Nguyen, Hoan Anh and Nguyen, Tung Thanh and Wilson, Gary and Nguyen, Anh Tuan and Kim, Miryung and Nguyen, Tien N.},
title = {A Graph-Based Approach to API Usage Adaptation},
year = {2010},
issue_date = {October 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {45},
number = {10},
issn = {0362-1340},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/1932682.1869486},
doi = {10.1145/1932682.1869486},
abstract = {Reusing existing library components is essential for reducing the cost of software development and maintenance. When library components evolve to accommodate new feature requests, to fix bugs, or to meet new standards, the clients of software libraries often need to make corresponding changes to correctly use the updated libraries. Existing API usage adaptation techniques support simple adaptation such as replacing the target of calls to a deprecated API, however, cannot handle complex adaptations such as creating a new object to be passed to a different API method, or adding an exception handling logic that surrounds the updated API method calls.This paper presents LIBSYNC that guides developers in adapting API usage code by learning complex API usage adaptation patterns from other clients that already migrated to a new library version (and also from the API usages within the library's test code). LIBSYNC uses several graph-based techniques (1) to identify changes to API declarations by comparing two library versions, (2) to extract associated API usage skeletons before and after library migration, and (3) to compare the extracted API usage skeletons to recover API usage adaptation patterns. Using the learned adaptation patterns, LIBSYNC recommends the locations and edit operations for adapting API usages. The evaluation of LIBSYNC on real-world software systems shows that it is highly correct and useful with a precision of 100% and a recall of 91%.},
journal = {SIGPLAN Not.},
month = oct,
pages = {302–321},
numpages = {20},
keywords = {software evolution, API usage adaptation, API evolution, program differencing, API usage model}
}

@inproceedings{10.1145/2543728.2543741,
author = {Li, Huiqing and Thompson, Simon and Lamela Seijas, Pablo and Francisco, Miguel Angel},
title = {Automating Property-Based Testing of Evolving Web Services},
year = {2014},
isbn = {9781450326193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/2543728.2543741},
doi = {10.1145/2543728.2543741},
abstract = {Web services are the most widely used service technology that drives the Service-Oriented Computing~(SOC) paradigm. As a result, effective testing of web services is getting increasingly important. In this paper, we present a framework and toolset for testing web services and for evolving test code in sync with the evolution of web services. Our approach to testing web services is based on the Erlang programming language and QuviQ QuickCheck, a property-based testing tool written in Erlang, and our support for test code evolution is added to Wrangler, the Erlang refactoring tool.The key components of our system include the automatic generation of initial test code, the inference of web service interface changes between versions, the provision of a number of domain specific refactorings and the automatic generation of refactoring scripts for evolving the test code. Our framework provides users with a powerful and expressive web service testing framework, while minimising users' effort in creating, maintaining and evolving the test model. The framework presented in this paper can be used by both web service providers and consumers, and can be used to test web services written in whatever language; the approach advocated here could also be adopted in other property-based testing frameworks and refactoring tools.},
booktitle = {Proceedings of the ACM SIGPLAN 2014 Workshop on Partial Evaluation and Program Manipulation},
pages = {169–180},
numpages = {12},
keywords = {api evolution, property-based testing, wrangler, erlang, wsdl, quickcheck, web service},
location = {San Diego, California, USA},
series = {PEPM '14}
}

@inproceedings{10.1145/1370175.1370203,
author = {Xing, Zhenchang and Stroulia, Eleni},
title = {The JDEvAn Tool Suite in Support of Object-Oriented Evolutionary Development},
year = {2008},
isbn = {9781605580791},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/1370175.1370203},
doi = {10.1145/1370175.1370203},
booktitle = {Companion of the 30th International Conference on Software Engineering},
pages = {951–952},
numpages = {2},
keywords = {model differencing, refactoring detection, asynchronous api evolution, evolutionary software development},
location = {Leipzig, Germany},
series = {ICSE Companion '08}
}

@inproceedings{10.1145/1134285.1134461,
author = {Freese, Tammo},
title = {Refactoring-Aware Version Control},
year = {2006},
isbn = {1595933751},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/1134285.1134461},
doi = {10.1145/1134285.1134461},
abstract = {Today, refactorings are supported in some integrated development environments (IDEs). The refactoring operations can only work correctly if all source code that needs to be changed is available to the IDE. However, this precondition neither holds for application programming interface (API) evolution, nor in team development. The research presented in this paper aims to support refactoring in API evolution and team development by extending IDE and version control to allow refactoring-aware merging and migration.},
booktitle = {Proceedings of the 28th International Conference on Software Engineering},
pages = {953–956},
numpages = {4},
keywords = {application programming interface, version control, eclipse, library, software evolution, refactoring, subversion},
location = {Shanghai, China},
series = {ICSE '06}
}

@inproceedings{10.1145/3377812.3382124,
author = {Lamothe, Maxime},
title = {Bridging the Divide between API Users and API Developers by Mining Public Code Repositories},
year = {2020},
isbn = {9781450371223},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/3377812.3382124},
doi = {10.1145/3377812.3382124},
abstract = {Software application programming interfaces (APIs) are a ubiquitous part of Software Engineering. The evolution of these APIs requires constant effort from their developers and users alike. API developers must constantly balance keeping their products modern whilst keeping them as stable as possible. Meanwhile, API users must continually be on the lookout to adapt to changes that could break their applications. As APIs become more numerous, users are challenged by a myriad of choices and information on which API to use. Current research attempts to provide automatic documentation, code examples, and code completion to make API evolution more scalable for users. Our work will attempt to establish practical and scalable API evolution guidelines and tools based on public code repositories, to aid both API users and API developers.This thesis focuses on investigating the use of public code repositories provided by the open-source community to improve software API engineering practices. More specifically, I seek to improve software engineering practices linked to API evolution, both from the perspective of API users and API developers. To achieve this goal, I will apply quantitative and qualitative research methods to understand the problems at hand. I will then mine public code repositories to develop novel solutions to these problems.},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering: Companion Proceedings},
pages = {178–181},
numpages = {4},
location = {Seoul, South Korea},
series = {ICSE '20}
}

@inproceedings{10.1145/3196398.3196476,
author = {Spinellis, Diomidis},
title = {Documented Unix Facilities over 48 Years},
year = {2018},
isbn = {9781450357166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/3196398.3196476},
doi = {10.1145/3196398.3196476},
abstract = {The documented Unix facilities data set provides the details regarding the evolution of 15 596 unique facilities through 93 versions of Unix over a period of 48 years. It is based on the manual transcription of early scanned documents, on the curation of text obtained through optical character recognition, and on the automatic extraction of data from code available on the Unix History Repository. The data are categorized into user commands, system calls, C library functions, devices and special files, file formats and conventions, games et. al., miscellanea, system maintenance procedures and commands, and system kernel interfaces. A timeline view allows the visualization of the evolution across releases. The data can be used for empirical research regarding API evolution, system design, as well as technology adoption and trends.},
booktitle = {Proceedings of the 15th International Conference on Mining Software Repositories},
pages = {58–61},
numpages = {4},
location = {Gothenburg, Sweden},
series = {MSR '18}
}

@inproceedings{10.1145/1449913.1449939,
author = {\c{S}avga, Ilie and Rudolf, Michael and G\"{o}tz, Sebastian and A\ss{}mann, Uwe},
title = {Practical Refactoring-Based Framework Upgrade},
year = {2008},
isbn = {9781605582672},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/1449913.1449939},
doi = {10.1145/1449913.1449939},
abstract = {Although the API of a software framework should stay stable, in practice it often changes during maintenance. When deploying a new framework version such changes may invalidate plugins - modules that used one of its previous versions. While manual plugin adaptation is expensive and error-prone, automatic adaptation demands cumbersome specifications, which the developers are reluctant to write and maintain. Basing on the history of structural framework changes (refactorings), in our previous work we formally defined how to automatically derive an adaptation layer that shields plugins from framework changes. In this paper we make our approach practical. Two case studies of unconstrained API evolution show that our approach scales in a large number of adaptation scenarios and comparing to other adaptation techniques. The evaluation of our logic-based tool ComeBack! demonstrates that it can adapt efficiently most of the problem-causing API refactorings.},
booktitle = {Proceedings of the 7th International Conference on Generative Programming and Component Engineering},
pages = {171–180},
numpages = {10},
keywords = {frameworks, adaptation, refactoring, maintenance},
location = {Nashville, TN, USA},
series = {GPCE '08}
}

@inproceedings{10.5555/2825041.2825044,
author = {Espinha, Tiago and Zaidman, Andy and Gross, Hans-Gerhard},
title = {Web API Fragility: How Robust is Your Mobile Application?},
year = {2015},
isbn = {9781479919345},
publisher = {IEEE Press},
abstract = {Web APIs provide a systematic and extensible approach for application-to-application interaction. A large number of mobile applications makes use of web APIs to integrate services into apps. Each Web API's evolution pace is determined by their respective developer and mobile application developers are forced to accompany the API providers in their software evolution tasks. In this paper we investigate whether and how mobile application developers deal with the added distress of web APIs evolving. In particular, we studied how robust 43 high profile mobile applications are when dealing with mutated web API responses. Additionally, we interviewed three mobile application developers to better understand their choices and trade-offs regarding web API integration.},
booktitle = {Proceedings of the Second ACM International Conference on Mobile Software Engineering and Systems},
pages = {12–21},
numpages = {10},
location = {Florence, Italy},
series = {MOBILESoft '15}
}

@article{10.1145/1400097.1400099,
author = {McKenney, Paul E. and Walpole, Jonathan},
title = {Introducing Technology into the Linux Kernel: A Case Study},
year = {2008},
issue_date = {July 2008},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {5},
issn = {0163-5980},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/1400097.1400099},
doi = {10.1145/1400097.1400099},
abstract = {There can be no doubt that a great many technologies have been added to Linux™ over the past ten years. What is less well-known is that it is often necessary to introduce a large amount of Linux into a given technology in order to successfully introduce that technology into Linux. This paper illustrates such an introduction of Linux into technology with Read-Copy Update (RCU). The RCU API's evolution over time clearly shows that Linux's extremely diverse set of workloads and platforms has changed RCU to a far greater degree than RCU has changed Linux---and it is reasonable to expect that other technologies that might be proposed for inclusion into Linux would face similar challenges. In addition, this paper presents a summary of lessons learned and an attempt to foresee what additional challenges Linux might present to RCU.},
journal = {SIGOPS Oper. Syst. Rev.},
month = jul,
pages = {4–17},
numpages = {14}
}

@inproceedings{10.5555/2820518.2820599,
author = {Sawant, Anand Ashok and Bacchelli, Alberto},
title = {A Dataset for API Usage},
year = {2015},
isbn = {9780769555942},
publisher = {IEEE Press},
abstract = {An Application Programming Interface (API) provides a specific set of functionalities to a developer. The main aim of an API is to encourage the reuse of already existing functionality. There has been some work done into API popularity trends, API evolution and API usage. For all the aforementioned research avenues there has been a need to mine the usage of an API in order to perform any kind of analysis. Each one of the approaches that has been employed in the past involved a certain degree of inaccuracy as there was no type check that takes place. We introduce an approach that takes type information into account while mining API method invocations and annotation usages. This approach accurately makes a connection between a method invocation and the class of the API to which the method belongs to. We try collecting as many usages of an API as possible, this is achieved by targeting projects hosted on GitHub. Additionally, we look at the history of every project to collect the usage of an API from earliest version onwards. By making such a large and rich dataset public, we hope to stimulate some more research in the field of APIs with the aid of accurate API usage samples.},
booktitle = {Proceedings of the 12th Working Conference on Mining Software Repositories},
pages = {506–509},
numpages = {4},
location = {Florence, Italy},
series = {MSR '15}
}

@inproceedings{10.1145/3361149.3361164,
author = {L\"{u}bke, Daniel and Zimmermann, Olaf and Pautasso, Cesare and Zdun, Uwe and Stocker, Mirko},
title = {Interface Evolution Patterns: Balancing Compatibility and Extensibility across Service Life Cycles},
year = {2019},
isbn = {9781450362061},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/3361149.3361164},
doi = {10.1145/3361149.3361164},
abstract = {Remote Application Programming Interfaces (APIs) are technology enablers for distributed systems and cloud-native application development. API providers find it hard to design their remote APIs so that they can be evolved easily; refactoring and extending an API while preserving backward compatibility is particularly challenging. If APIs are evolved poorly, clients are critically impacted; high costs to adapt and compensate for downtimes may result. For instance, if an API provider publishes a new incompatible API version, existing clients might break and not function properly until they are upgraded to support the new version. Hence, applying adequate strategies for evolving service APIs is one of the core problems in API governance, which in turn is a prerequisite for successfully integrating service providers with their clients in the long run. Although many patterns and pattern languages are concerned with API, service design, and related integration technologies, patterns guiding the evolution of APIs are missing to date. Extending our emerging pattern language on Microservice API Patterns (MAP), we introduce a set of patterns focusing on API evolution strategies in this paper: API Description, Version Identifier, Semantic Versioning, Eternal Lifetime Guarantee, Limited Lifetime Guarantee, Two in Production, Aggressive Obsolescence, and Experimental Preview. The patterns were mined from public Web APIs and industry projects the authors had been involved in.},
booktitle = {Proceedings of the 24th European Conference on Pattern Languages of Programs},
articleno = {15},
numpages = {24},
location = {Irsee, Germany},
series = {EuroPLop '19}
}

@inproceedings{10.1145/3361242.3361246,
author = {Xi, Yaoguo and Shen, Liwei and Gui, Yukun and Zhao, Wenyun},
title = {Migrating Deprecated API to Documented Replacement: Patterns and Tool},
year = {2019},
isbn = {9781450377010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/3361242.3361246},
doi = {10.1145/3361242.3361246},
abstract = {Deprecation is commonly leveraged to preserve the backwards compatibility in API clients during API evolution. Client developers then usually encounter migration tasks when relying on a new version of API. Manually migrating a deprecated API to its replacement may be tedious and time-consuming. Existing research has focused on the requirements of automated migration however has limitations on the consistency and granularity of the generated migration pathway. In this paper, we propose an approach for migrating deprecated APIs to their replacements which are explicitly documented in the code documentation. A migration pattern including the migration type and the migration strategy is first introduced to describe the difference and the code change from a deprecated API to its replacement. An automated process is then designed and implemented to construct the pattern for a specific deprecated API by reviewing the code documentation and analyzing the API source code. Based on the patterns, a tool named DAAMT is developed to locate deprecated APIs and to provide migration suggestions for API clients. An experimental study on open-source Java projects and a user study is performing utilizing the approach. The results show that three-fourth of the deprecated APIs with documented replacements involved in the projects can be automatically migrated. In addition, the DAAMT tool can improve the efficiency and accuracy of the tasks compared with the manual migration.},
booktitle = {Proceedings of the 11th Asia-Pacific Symposium on Internetware},
articleno = {15},
numpages = {10},
keywords = {Migration Pattern, API Migration, Deprecated API},
location = {Fukuoka, Japan},
series = {Internetware '19}
}

@inproceedings{10.1109/ICPC.2017.3,
author = {Mostafa, Shaikh and Rodriguez, Rodney and Wang, Xiaoyin},
title = {NetDroid: Summarizing Network Behavior of Android Apps for Network Code Maintenance},
year = {2017},
isbn = {9781538605356},
publisher = {IEEE Press},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1109/ICPC.2017.3},
doi = {10.1109/ICPC.2017.3},
abstract = {Network access is one of the most common features of Android applications. Statistics show that almost 80% of Android apps ask for network permission and thus may have some network-related features. Android apps may access multiple servers to retrieve or post various types of data, and the code to handle such network features often needs to change as a result of server API evolution or the content change of data transferred. Since various network code is used by multiple features, maintenance of network-related code is often difficult because the code may scatter in different places in the code base, and it may not be easy to predict the impact of a code change to the network behavior of an Android app. In this paper, we present an approach to statically summarize network behavior from the byte code of Android apps. Our approach is based on string taint analysis, and generates a summary of network requests by statically estimating the possible values of network API arguments. To evaluate our technique, we applied our technique to top 500 android apps from the official Google Play market, and the result shows that our approach is able to summarize network behavior for most apps efficiently (averagely less than 50 second for an app). Furthermore, we performed an empirical evaluation on 8 real-world maintenance tasks extracted from bug reports of open-source Android projects on Github. The empirical evaluation shows that our technique is effective in locating relevant network code.},
booktitle = {Proceedings of the 25th International Conference on Program Comprehension},
pages = {165–175},
numpages = {11},
location = {Buenos Aires, Argentina},
series = {ICPC '17}
}

@inproceedings{10.1145/2554850.2559925,
author = {Kim, Jungil and Lee, Eunjoo},
title = {The Effect of IMPORT Change in Software Change History},
year = {2014},
isbn = {9781450324694},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/2554850.2559925},
doi = {10.1145/2554850.2559925},
abstract = {Source code change analysis in the project history is one of main issues in mining software repositories, which incorporates change prediction, API evolution and refactoring, etc. In the previous studies, fine-grained source code changes, that is, code level changes, were used to find source code change patterns. In this paper, we closely investigate IMPORT change type, which has not been unnoticed. At first, we performed modifying the existing change extraction tool, change distiller [3], to extract IMPORT change history. And then, we extracted commit history data from project repository of eclipse CDT and IDT. Change types for each change in commit history data have been determined using change types in [3] and IMPORT change types defined in this work. Finally, we analyzed the effect of IMPORT change using the frequency of each change type occurred in the commit history. Experimental result shows that the IMPORT change meaningfully affects other changes and it would be better to consider IMPORT change types in change analysis work.},
booktitle = {Proceedings of the 29th Annual ACM Symposium on Applied Computing},
pages = {1753–1754},
numpages = {2},
keywords = {change coupling, data mining, coupling measurement, mining software repository},
location = {Gyeongju, Republic of Korea},
series = {SAC '14}
}

@inproceedings{10.1145/2950290.2950306,
author = {Hora, Andr\'{e} and Valente, Marco Tulio and Robbes, Romain and Anquetil, Nicolas},
title = {When Should Internal Interfaces Be Promoted to Public?},
year = {2016},
isbn = {9781450342186},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/2950290.2950306},
doi = {10.1145/2950290.2950306},
abstract = { Commonly, software systems have public (and stable) interfaces, and internal (and possibly unstable) interfaces. Despite being discouraged, client developers often use internal interfaces, which may cause their systems to fail when they evolve. To overcome this problem, API producers may promote internal interfaces to public. In practice, however, API producers have no assistance to identify public interface candidates. In this paper, we study the transition from internal to public interfaces. We aim to help API producers to deliver a better product and API clients to benefit sooner from public interfaces. Our empirical investigation on five widely adopted Java systems present the following observations. First, we identified 195 promotions from 2,722 internal interfaces. Second, we found that promoted internal interfaces have more clients. Third, we predicted internal interface promotion with precision between 50%-80%, recall 26%-82%, and AUC 74%-85%. Finally, by applying our predictor on the last version of the analyzed systems, we automatically detected 382 public interface candidates. },
booktitle = {Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering},
pages = {278–289},
numpages = {12},
keywords = {API Usage, Internal Interface Analysis, Software Evolution},
location = {Seattle, WA, USA},
series = {FSE 2016}
}

@inproceedings{10.1145/3180155.3180212,
author = {Hora, Andre and Silva, Danilo and Valente, Marco Tulio and Robbes, Romain},
title = {Assessing the Threat of Untracked Changes in Software Evolution},
year = {2018},
isbn = {9781450356381},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/3180155.3180212},
doi = {10.1145/3180155.3180212},
abstract = {While refactoring is extensively performed by practitioners, many Mining Software Repositories (MSR) approaches do not detect nor keep track of refactorings when performing source code evolution analysis. In the best case, keeping track of refactorings could be unnecessary work; in the worst case, these untracked changes could significantly affect the performance of MSR approaches. Since the extent of the threat is unknown, the goal of this paper is to assess whether it is significant. Based on an extensive empirical study, we answer positively: we found that between 10 and 21% of changes at the method level in 15 large Java systems are untracked. This results in a large proportion (25%) of entities that may have their histories split by these changes, and a measurable effect on at least two MSR approaches. We conclude that handling untracked changes should be systematically considered by MSR studies.},
booktitle = {Proceedings of the 40th International Conference on Software Engineering},
pages = {1102–1113},
numpages = {12},
keywords = {software evolution, refactoring, mining software repositories},
location = {Gothenburg, Sweden},
series = {ICSE '18}
}

@inproceedings{10.1145/3213846.3213857,
author = {Li, Li and Bissyand\'{e}, Tegawend\'{e} F. and Wang, Haoyu and Klein, Jacques},
title = {CiD: Automating the Detection of API-Related Compatibility Issues in Android Apps},
year = {2018},
isbn = {9781450356992},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/3213846.3213857},
doi = {10.1145/3213846.3213857},
abstract = {The Android Application Programming Interface provides the necessary building blocks for app developers to harness the functionalities of the Android devices, including for interacting with services and accessing hardware. This API thus evolves rapidly to meet new requirements for security, performance and advanced features, creating a race for developers to update apps. Unfortunately, given the extent of the API and the lack of automated alerts on important changes, Android apps are suffered from API-related compatibility issues. These issues can manifest themselves as runtime crashes creating a poor user experience. We propose in this paper an automated approach named CiD for systematically modelling the lifecycle of the Android APIs and analysing app bytecode to flag usages that can lead to potential compatibility issues. We demonstrate the usefulness of CiD by helping developers repair their apps, and we validate that our tool outperforms the state-of-the-art on benchmark apps that take into account several challenges for automatic detection.},
booktitle = {Proceedings of the 27th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {153–163},
numpages = {11},
keywords = {CiD, Android, Framework Base, API-related Compatibility Issue},
location = {Amsterdam, Netherlands},
series = {ISSTA 2018}
}

@article{10.1145/1543405.1543429,
author = {Daughtry, John M. and Farooq, Umer and Myers, Brad A. and Stylos, Jeffrey},
title = {API Usability: Report on Special Interest Group at CHI},
year = {2009},
issue_date = {July 2009},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {4},
issn = {0163-5948},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/1543405.1543429},
doi = {10.1145/1543405.1543429},
abstract = {The 27th annual International Conference on Human Factors in Computing (CHI) convened in Boston, MA (USA) from April 4-9, 2009. Included in this year's technical program was a special interest group (SIG) meeting on API usability. This report summarizes the SIG, emphasizing the primary takeaways, which include a greater understanding of the types of APIs, case studies, and a place to share our multi-disciplinary results.},
journal = {SIGSOFT Softw. Eng. Notes},
month = jul,
pages = {27–29},
numpages = {3},
keywords = {human-computer interaction, empirical studies of programmers (ESP), software libraries, application program interface (API), software engineering, psychology of programming, natural programming}
}

@inproceedings{10.1145/2508075.2508093,
author = {\v{S}trobl, Roman and Tron\'{\i}\v{c}ek, Zden\v{e}k},
title = {Migration from Deprecated API in Java},
year = {2013},
isbn = {9781450319959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/2508075.2508093},
doi = {10.1145/2508075.2508093},
abstract = {When software components evolve, they change interfaces. Members that are obsolete are marked as deprecated and new members are added. We deal with the problem of migration from deprecated members to their replacement. We implemented two tools: Java Source Code Update Tool, which updates the source code based on a configuration file, and a generator, which heuristically figures out how to migrate from deprecated members and generates the configuration file. We evaluated these tools on five open source projects and the results are very encouraging.},
booktitle = {Proceedings of the 2013 Companion Publication for Conference on Systems, Programming, &amp; Applications: Software for Humanity},
pages = {85–86},
numpages = {2},
keywords = {component upgrade, java, software evolution, deprecated API, migration},
location = {Indianapolis, Indiana, USA},
series = {SPLASH '13}
}

@inproceedings{10.1145/1176617.1176668,
author = {Dig, Danny and Johnson, Ralph},
title = {Automated Upgrading of Component-Based Applications},
year = {2006},
isbn = {159593491X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/1176617.1176668},
doi = {10.1145/1176617.1176668},
abstract = {Frameworks and libraries change their APIs. Migrating an application to the new API is tedious and disrupts the development process. Although some tools and ideas have been proposed to solve the evolution of APIs, most updates are done manually. Our study of the API changes in five components revealed that over 80% of the changes that break existing applications are caused by refactorings. This suggests that refactoring-based migration tools should be used to effectively upgrade applications. We propose an approach that is both automated and safe, without any overhead on the component producers. First, component refactorings are automatically detected (either inferred or recorded), then they are incorporated into applications by replaying.},
booktitle = {Companion to the 21st ACM SIGPLAN Symposium on Object-Oriented Programming Systems, Languages, and Applications},
pages = {675–676},
numpages = {2},
keywords = {frameworks, refactoring, component reuse, libraries},
location = {Portland, Oregon, USA},
series = {OOPSLA '06}
}

@inproceedings{10.1145/2889160.2889208,
author = {Dig, Danny and Johnson, Ralph and Marinov, Darko and Bailey, Brian and Batory, Don},
title = {COPE: Vision for a Change-Oriented Programming Environment},
year = {2016},
isbn = {9781450342056},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/2889160.2889208},
doi = {10.1145/2889160.2889208},
abstract = {Software engineering involves a lot of change as code artifacts are not only created once but maintained over time. In the last 25 years, major paradigms of program development have arisen -- agile development with refactorings, software product lines, moving sequential code to multicore or cloud, etc. Each is centered on particular kinds of change; their conceptual foundations rely on transformations that (semi-) automate these changes.We are exploring how transformations can be placed at the center of software development in future IDEs, and when such a view can provide benefits over the traditional view. COPE, a Change-Oriented Programming Environment, looks at 5 activities: (1) analyze what changes programmers typically make and how they perceive, recall, and communicate changes, (2) automate transformations to make it easier to apply and script changes, (3) develop tools that compose and manipulate transformations to make it easier to reuse them, (4) integrate transformations with version control to provide better ways for archiving and understanding changes, and (5) develop tools that infer higher-level transformations from lower-level changes. Characterizing software development in terms of transformations is an essential step to take software engineering from manual development to (semi-) automated development of software.},
booktitle = {Proceedings of the 38th International Conference on Software Engineering Companion},
pages = {773–776},
numpages = {4},
location = {Austin, Texas},
series = {ICSE '16}
}

@inproceedings{10.1145/2970276.2970312,
author = {Wei, Lili and Liu, Yepang and Cheung, Shing-Chi},
title = {Taming Android Fragmentation: Characterizing and Detecting Compatibility Issues for Android Apps},
year = {2016},
isbn = {9781450338455},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/2970276.2970312},
doi = {10.1145/2970276.2970312},
abstract = { Android ecosystem is heavily fragmented. The numerous combinations of different device models and operating system versions make it impossible for Android app developers to exhaustively test their apps. As a result, various compatibility issues arise, causing poor user experience. However, little is known on the characteristics of such fragmentation-induced compatibility issues and no mature tools exist to help developers quickly diagnose and fix these issues. To bridge the gap, we conducted an empirical study on 191 real-world compatibility issues collected from popular open-source Android apps. Our study characterized the symptoms and root causes of compatibility issues, and disclosed that the patches of these issues exhibit common patterns. With these findings, we propose a technique named FicFinder to automatically detect compatibility issues in Android apps. FicFinder performs static code analysis based on a model that captures Android APIs as well as their associated context by which compatibility issues are triggered. FicFinder reports actionable debugging information to developers when it detects potential issues. We evaluated FicFinder with 27 large-scale open-source Android apps. The results show that FicFinder can precisely detect compatibility issues in these apps and uncover previously-unknown issues. },
booktitle = {Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering},
pages = {226–237},
numpages = {12},
keywords = {compatibility issues, Android fragmentation},
location = {Singapore, Singapore},
series = {ASE 2016}
}

@inproceedings{10.1145/3293882.3330564,
author = {Cai, Haipeng and Zhang, Ziyi and Li, Li and Fu, Xiaoqin},
title = {A Large-Scale Study of Application Incompatibilities in Android},
year = {2019},
isbn = {9781450362245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/3293882.3330564},
doi = {10.1145/3293882.3330564},
abstract = {The rapid expansion of the Android ecosystem is accompanied by continuing diversification of platforms and devices, resulting in increasing incompatibility issues which damage user experiences and impede app development productivity. In this paper, we conducted a large-scale, longitudinal study of compatibility issues in 62,894 benign apps developed in the past eight years, to understand the symptoms and causes of these issues. We further investigated the incompatibilities that are actually exercised at runtime through the system logs and execution traces of 15,045 apps. Our study revealed that, among others, (1) compatibility issues were prevalent and persistent at both installation and run time, with greater prevalence of run-time incompatibilities, (2) there were no certain Android versions that consistently saw more or less app incompatibilities than others, (3) installation-time incompatibilities were strongly correlated with the minSdkVersion specified in apps, while run-time incompatibilities were most significantly correlated with the underlying platform’s API level, and (4) installation-time incompatibilities were mostly due to apps’ use of architecture-incompatible native libraries, while run-time incompatibilities were mostly due to API changes during SDK evolution. We offered further insights into app incompatibilities, as well as recommendations on dealing with the issues for bother developers and end users of Android apps.},
booktitle = {Proceedings of the 28th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {216–227},
numpages = {12},
keywords = {compatibility, run-time failure, installation failure, Android},
location = {Beijing, China},
series = {ISSTA 2019}
}

@inproceedings{10.1109/ICSE-SEIP.2017.11,
author = {Sohan, S M and Anslow, Craig and Maurer, Frank},
title = {Automated Example Oriented REST API Documentation at Cisco},
year = {2017},
isbn = {9781538627174},
publisher = {IEEE Press},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1109/ICSE-SEIP.2017.11},
doi = {10.1109/ICSE-SEIP.2017.11},
abstract = {Generating and maintaining an up-to-date API documentation is a challenging problem for evolving REST APIs. At Cisco, we've used SpyREST, an automated REST API documentation tool, via our functional tests to solve this problem with one of our APIs for a cyber security application over the past eighteen months. Using this approach, we've avoided the need for extensive manual effort by leveraging our test code to also generate a continuously updated API documentation as the API evolved. Our always-updated API documentation has helped creating a fast feedback loop between the developers and QA engineers. The findings from this paper can be used by practitioners to introduce automation to reduce the manual effort associated to their REST API documentation process.},
booktitle = {Proceedings of the 39th International Conference on Software Engineering: Software Engineering in Practice Track},
pages = {213–222},
numpages = {10},
keywords = {documentation, tool, API, test, case study, automation, REST, HTTP, web API},
location = {Buenos Aires, Argentina},
series = {ICSE-SEIP '17}
}

@inproceedings{10.1145/1900008.1900146,
author = {Cho, Hyun and Gray, Jeff},
title = {A Domain-Specific Modeling Language for Scientific Data Composition and Interoperability},
year = {2010},
isbn = {9781450300643},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/1900008.1900146},
doi = {10.1145/1900008.1900146},
abstract = {Domain-Specific Modeling Languages (DSMLs) can offer assistance to domain experts, who may not be computer scientists, by providing notations and semantic constructs that align with abstractions from a particular domain. In this paper, we describe our design and application of a DSML in the area of data composition and interoperability. In particular, we introduce our recent effort to design a DSML to assist with interoperability issues across scientific software applications (e.g., composing scientific data in different file structures and integrating scientific data with data gathering devices). Currently, several different scientific data file specifications have been proposed (e.g., CID, netCDF, and HDF). Each file specification is optimized to manage a specific data type efficiently. Thus, each file specification has evolved with slightly different notions and implementation technologies. These differences led to the need for an environment that provides interoperability among the different specification formats. In this paper, we introduce our framework, supported by a DSML, that provides functionality to visually model the data composition and integration concepts independent from a particular data file specification.},
booktitle = {Proceedings of the 48th Annual Southeast Regional Conference},
articleno = {107},
numpages = {4},
keywords = {data composition, data integration, domain-specific modeling language (DSML), file format, metamodeling, verification},
location = {Oxford, Mississippi},
series = {ACM SE '10}
}

@inproceedings{10.1145/3238147.3238185,
author = {He, Dongjie and Li, Lian and Wang, Lei and Zheng, Hengjie and Li, Guangwei and Xue, Jingling},
title = {Understanding and Detecting Evolution-Induced Compatibility Issues in Android Apps},
year = {2018},
isbn = {9781450359375},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/3238147.3238185},
doi = {10.1145/3238147.3238185},
abstract = {The frequent release of Android OS and its various versions bring many compatibility issues to Android Apps. This paper studies and addresses such evolution-induced compatibility problems. We conduct an extensive empirical study over 11 different Android versions and 4,936 Android Apps. Our study shows that there are drastic API changes between adjacent Android versions, with averagely 140.8 new types, 1,505.6 new methods, and 979.2 new fields being introduced in each release. However, the Android Support Library (provided by the Android OS) only supports less than 23% of the newly added methods, with much less support for new types and fields. As a result, 91.84% of Android Apps write additional code to support different OS versions. Furthermore, 88.65% of the supporting codes share a common pattern, which directly compares variable android.os.Build.VERSION.SDK_INT with a constant version number, to use an API of particular versions. Based on our findings, we develop a new tool called IctApiFinder, to detect incompatible API usages in Android applications. IctApiFinder effectively computes the OS versions on which an API may be invoked, using an inter-procedural data-flow analysis framework. It detects numerous incompatible API usages in 361 out of 1,425 Apps. Compared to Android Lint, IctApiFinder is sound and able to reduce the false positives by 82.1%. We have reported the issues to 13 Apps developers. At present, 5 of them have already been confirmed by the original developers and 3 of them have already been fixed.},
booktitle = {Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering},
pages = {167–177},
numpages = {11},
keywords = {Android compatibility, Android evolution, incompatible API usage},
location = {Montpellier, France},
series = {ASE 2018}
}

@inproceedings{10.1109/ICPC.2019.00052,
author = {Xu, Shengzhe and Dong, Ziqi and Meng, Na},
title = {Meditor: Inference and Application of API Migration Edits},
year = {2019},
publisher = {IEEE Press},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1109/ICPC.2019.00052},
doi = {10.1109/ICPC.2019.00052},
abstract = {Developers build programs based on software libraries. When a library evolves, programmers need to migrate their client code from the library's old release(s) to new release(s). Due to the API backwards incompatibility issues, such code migration may require developers to replace API usage and apply extra edits (e.g., statement insertions or deletions) to ensure the syntactic or semantic correctness of migrated code. Existing tools extract API replacement rules without handling the additional edits necessary to fulfill a migration task. This paper presents our novel approach, Meditor, which extracts and applies the necessary edits together with API replacement changes.Meditor has two phases: inference and application of migration edits. For edit inference, Meditor mines open source repositories for migration-related (MR) commits, and conducts program dependency analysis on changed Java files to locate and cluster MR code changes. From these changes, Meditor further generalizes API migration edits by abstracting away unimportant details (e.g., concrete variable identifiers). For edit application, Meditor matches a given program with inferred edits to decide which edit is applicable, customizes each applicable edit, and produces a migrated version for developers to review.We applied Meditor to four popular libraries: Lucene, Craft-Bukkit, Android SDK, and Commons IO. By searching among 602,249 open source projects on GitHub, Meditor identified 1,368 unique migration edits. Among these edits, 885 edits were extracted from single updated statements, while the other 483 more complex edits were from multiple co-changed statements. We sampled 937 inferred edits for manual inspection and found all of them to be correct. Our evaluation shows that Meditor correctly applied code migrations in 218 out of 225 cases. This research will help developers automatically adapt client code to different library versions.},
booktitle = {Proceedings of the 27th International Conference on Program Comprehension},
pages = {335–346},
numpages = {12},
keywords = {program dependency analysis, API migration edits, automatic program transformation},
location = {Montreal, Quebec, Canada},
series = {ICPC '19}
}

@inproceedings{10.1145/3183519.3183537,
author = {Au\'{e}, Joop and Aniche, Maur\'{\i}cio and Lobbezoo, Maikel and van Deursen, Arie},
title = {An Exploratory Study on Faults in Web API Integration in a Large-Scale Payment Company},
year = {2018},
isbn = {9781450356596},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/3183519.3183537},
doi = {10.1145/3183519.3183537},
abstract = {Service-oriented architectures are more popular than ever, and increasingly companies and organizations depend on services offered through Web APIs. The capabilities and complexity of Web APIs differ from service to service, and therefore the impact of API errors varies. API problem cases related to Adyen's payment service were found to have direct considerable impact on API consumer applications. With more than 60,000 daily API errors, the potential impact is enormous. In an effort to reduce the impact of API related problems, we analyze 2.43 million API error responses to identify the underlying faults. We quantify the occurrence of faults in terms of the frequency and impacted API consumers. We also challenge our quantitative results by means of a survey with 40 API consumers. Our results show that 1) faults in API integration can be grouped into 11 general causes: invalid user input, missing user input, expired request data, invalid request data, missing request data, insufficient permissions, double processing, configuration, missing server data, internal and third party, 2) most faults can be attributed to the invalid or missing request data, and most API consumers seem to be impacted by faults caused by invalid request data and third party integration; and 3) insufficient guidance on certain aspects of the integration and on how to recover from errors is an important challenge to developers.},
booktitle = {Proceedings of the 40th International Conference on Software Engineering: Software Engineering in Practice},
pages = {13–22},
numpages = {10},
keywords = {web API integration, webservices, web engineering},
location = {Gothenburg, Sweden},
series = {ICSE-SEIP '18}
}

@inbook{10.1145/3368089.3409735,
author = {Wang, Jiawei and Li, Li and Liu, Kui and Cai, Haipeng},
title = {Exploring How Deprecated Python Library APIs Are (Not) Handled},
year = {2020},
isbn = {9781450370431},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/3368089.3409735},
abstract = {In this paper, we present the first exploratory study of deprecated Python library APIs to understand the status quo of API deprecation in the realm of Python libraries. Specifically, we aim to comprehend how deprecated library APIs are declared and documented in practice by their maintainers, and how library users react to them. By thoroughly looking into six reputed Python libraries and 1,200 GitHub projects, we experimentally observe that API deprecation is poorly handled by library contributors, which subsequently introduce difficulties for Python developers to resolve the usage of deprecated library APIs. This empirical evidence suggests that our community should take immediate actions to appropriately handle the deprecation of Python library APIs.},
booktitle = {Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {233–244},
numpages = {12}
}

@inproceedings{10.1145/3205651.3208311,
author = {Orlov, Michael},
title = {Towards Modular Large-Scale Darwinian Software Improvement},
year = {2018},
isbn = {9781450357647},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/3205651.3208311},
doi = {10.1145/3205651.3208311},
abstract = {This paper proposes to explore a software engineer-assisted method for evolutionarily improving large-scale software systems. A framework is outlined for selecting and evolving specific components of such systems, while avoiding treating the complete software as a single independent individual in the population, thereby forgoing the high costs of that approach.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference Companion},
pages = {1614–1615},
numpages = {2},
keywords = {large-scale software systems, genetic improvement, genetic programming},
location = {Kyoto, Japan},
series = {GECCO '18}
}

@inproceedings{10.5555/2032497.2032506,
author = {Mileva, Yana Momchilova and Wasylkowski, Andrzej and Zeller, Andreas},
title = {Mining Evolution of Object Usage},
year = {2011},
isbn = {9783642226540},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {As software evolves, so does the interaction between its components. But how can we check if components are updated consistently? By abstracting object usage into temporal properties, we can learn evolution patterns that express how object usage evolves over time. Software can then be checked against these patterns, revealing code that is in need of update: "Your check for isValidWidget() is now superseded by checkWidget()." In an evaluation of seven different versions of three open source projects, our LAMARCK tool was able to detect existing code issues with a precision of 33%-64% and to prevent such issues with a precision of 90%-100%.},
booktitle = {Proceedings of the 25th European Conference on Object-Oriented Programming},
pages = {105–129},
numpages = {25},
location = {Lancaster, UK},
series = {ECOOP'11}
}

@inproceedings{10.1145/2393596.2393661,
author = {Cossette, Bradley E. and Walker, Robert J.},
title = {Seeking the Ground Truth: A Retroactive Study on the Evolution and Migration of Software Libraries},
year = {2012},
isbn = {9781450316149},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/2393596.2393661},
doi = {10.1145/2393596.2393661},
abstract = {Application programming interfaces (APIs) are a common and industrially-relevant means for third-party software developers to reuse external functionality. Several techniques have been proposed to help migrate client code between library versions with incompatible APIs, but it is not clear how well these perform in an absolute sense. We present a retroactive study into the presence and nature of API incompatibilities between several versions of a set of Java-based software libraries; for each, we perform a detailed, manual analysis to determine what the correct adaptations are to migrate from the older to the newer version. In addition, we investigate whether any of a set of adaptation recommender techniques is capable of identifying the correct adaptations for library migration. We find that a given API incompatibility can typically be addressed by only one or two recommender techniques, but sometimes none serve. Furthermore, those techniques give correct recommendations, on average, in only about 20% of cases.},
booktitle = {Proceedings of the ACM SIGSOFT 20th International Symposium on the Foundations of Software Engineering},
articleno = {55},
numpages = {11},
keywords = {adaptive change, recommendation systems, API},
location = {Cary, North Carolina},
series = {FSE '12}
}

@article{10.1145/1457516.1457524,
author = {Jiau, Hewijin Christine and Chen, Jinghong Cox},
title = {Test Code Differencing for Test-Driven Refactoring Automation},
year = {2009},
issue_date = {January 2009},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {1},
issn = {0163-5948},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/1457516.1457524},
doi = {10.1145/1457516.1457524},
abstract = {Test-driven refactoring (TDR) requires the developer to finish test adaptation before applying refactoring. However, the current approaches of TDR usually compromise the principle of Test-First and make the refactoring intent implicit. The failed delivery of refactoring intent hinders the opportunity of test-driven refactoring automation (TDRA). In this paper, a test code differencing algorithm TestDiff is provided to extract refactoring intents from test adaptation. A tool, Refiner, is demonstrated and evaluated by real cases.},
journal = {SIGSOFT Softw. Eng. Notes},
month = jan,
pages = {1–10},
numpages = {10}
}

@article{10.1145/3418209,
author = {Boldi, Paolo and Gousios, Georgios},
title = {Fine-Grained Network Analysis for Modern Software Ecosystems},
year = {2020},
issue_date = {February 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {21},
number = {1},
issn = {1533-5399},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/3418209},
doi = {10.1145/3418209},
abstract = {Modern software development is increasingly dependent on components, libraries, and frameworks coming from third-party vendors or open-source suppliers and made available through a number of platforms (or forges). This way of writing software puts an emphasis on reuse and on composition, commoditizing the services that modern applications require. On the other hand, bugs and vulnerabilities in a single library living in one such ecosystem can affect, directly or by transitivity, a huge number of other libraries and applications. Currently, only product-level information on library dependencies is used to contain this kind of danger, but this knowledge often reveals itself too imprecise to lead to effective (and possibly automated) handling policies. We will discuss how fine-grained function-level dependencies can greatly improve reliability and reduce the impact of vulnerabilities on the whole software ecosystem.},
journal = {ACM Trans. Internet Technol.},
month = dec,
articleno = {1},
numpages = {14},
keywords = {security breaches, Software reuse, network analysis}
}

@inproceedings{10.1109/PESOS.2009.5068827,
author = {Borovskiy, Vadym and Mueller, Juergen and Schapranow, Matthieu-Patrick and Zeier, Alexander},
title = {Ensuring Service Backwards Compatibility with Generic Web Services},
year = {2009},
isbn = {9781424437160},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1109/PESOS.2009.5068827},
doi = {10.1109/PESOS.2009.5068827},
abstract = {Ensuring compatibility in service-oriented systems is a challenging task. This article addresses the challenge of maintaining Web service backwards compatibility. In particular, the authors suggest a new interface design technique called Generic Web Services that allows service providers to add new features to Web services without breaking compatibility with existing clients. This is achieved by partially shifting the semantics of service operations from design time to runtime by relaxing the operations signatures with identity parameters. Furthermore, the authors discuss the advantages and disadvantages of generic Web services. The article also contains an example that applies the aforementioned technique to a Web service from SAP Enterprise Services Workplace.},
booktitle = {Proceedings of the 2009 ICSE Workshop on Principles of Engineering Service Oriented Systems},
pages = {95–98},
numpages = {4},
series = {PESOS '09}
}

@article{10.1145/3106369,
author = {Trevi\~{n}o, Edgar S. Garc\'{\i}a and Hameed, Muhammad Zaid and Barria, Javier A},
title = {Data Stream Evolution Diagnosis Using Recursive Wavelet Density Estimators},
year = {2018},
issue_date = {February 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {1},
issn = {1556-4681},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/3106369},
doi = {10.1145/3106369},
abstract = {Data streams are a new class of data that is becoming pervasively important in a wide range of applications, ranging from sensor networks, environmental monitoring to finance. In this article, we propose a novel framework for the online diagnosis of evolution of multidimensional streaming data that incorporates Recursive Wavelet Density Estimators into the context of Velocity Density Estimation. In the proposed framework changes in streaming data are characterized by the use of local and global evolution coefficients. In addition, we propose for the analysis of changes in the correlation structure of the data a recursive implementation of the Pearson correlation coefficient using exponential discounting. Two visualization tools, namely temporal and spatial velocity profiles, are extended in the context of the proposed framework. These are the three main advantages of the proposed method over previous approaches: (1) the memory storage required is minimal and independent of any window size; (2) it has a significantly lower computational complexity; and (3) it makes possible the fast diagnosis of data evolution at all dimensions and at relevant combinations of dimensions with only one pass of the data. With the help of the four examples, we show the framework’s relevance in a change detection context and its potential capability for real world applications.},
journal = {ACM Trans. Knowl. Discov. Data},
month = jan,
articleno = {14},
numpages = {28},
keywords = {data stream evolution diagnosis, Data streams mining, velocity density estimation, incremental statistics}
}

@inproceedings{10.1145/2723742.2723743,
author = {Lamba, Yash and Khattar, Manisha and Sureka, Ashish},
title = {Pravaaha: Mining Android Applications for Discovering API Call Usage Patterns and Trends},
year = {2015},
isbn = {9781450334327},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/2723742.2723743},
doi = {10.1145/2723742.2723743},
abstract = {Software libraries and frameworks, consisting of a collection of Class and Interface definitions, provide a mechanism for code reuse by providing methods, APIs, components (generic functionality) and a support structure for developers to build applications, products and solutions. KitKat, Jelly Bean, Ice Cream Sandwich, Honeycomb and Gingerbread are different versions (open-source) of Android, one of the most popular mobile platforms in the world. In this paper, we present the results of our large-scale (consisting of 1, 120 open-source applications and 17.4 million lines of code) API usage analysis of Android applications. Our work is motivated by the need to mine actual Android API usage, frequent API call usage patterns and trends to understand and generate empirical data on how developers are using the mobile platform in their applications.Extracting popular and frequently-invoked methods, API packages and API call-usage patterns is useful to both the API Producers and API Consumers. For example, API Producers can view the quantitative data on API usage as a feedback from users on the relevance, usability and applicability of the respective APIs. We conduct a series of experiments on analysing the Android platform API usage (usage of different packages, usage of methods, usage across categories) and present the results of our analysis using graphs such as Bubble Chart, Radar Chart, Heat-Map for effective visualization of the results and for extraction of actionable information.},
booktitle = {Proceedings of the 8th India Software Engineering Conference},
pages = {10–19},
numpages = {10},
keywords = {Empirical Software Engineering and Measurements, Android Applications, Mining Software Repositories, API Call Usage Patterns},
location = {Bangalore, India},
series = {ISEC '15}
}

@inproceedings{10.1145/2801081.2801097,
author = {Chaikalis, Theodore and Chatzigeorgiou, Alexander and Ampatzoglou, Apostolos and Deligiannis, Ignatios},
title = {Assessing the Evolution of Quality in Java Libraries},
year = {2015},
isbn = {9781450333351},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/2801081.2801097},
doi = {10.1145/2801081.2801097},
abstract = {Libraries are increasingly employed in software practice to speed up the development process by reusing available and tested components. Software systems, that are available as libraries, are expected to be well-designed, because they have to adhere to specific principles, in order to accommodate the needs of multiple clients in a robust and stable way. Considering that most software libraries are continuously upgraded, in this paper we investigate the evolution of their quality over time. In particular, we perform a systematic case study to assess whether quality, in terms of three software metrics (CBO, LCOM, WMC), exhibits clear trends during the history of twenty analyzed libraries. The findings indicate that the examined software libraries can be considered as stable software projects in terms of quality, in the sense that in contrast to the general belief about software aging, their quality does not degrade over time.},
booktitle = {Proceedings of the 7th Balkan Conference on Informatics Conference},
articleno = {5},
numpages = {4},
keywords = {case studies, software quality, Software evolution analysis},
location = {Craiova, Romania},
series = {BCI '15}
}

@inproceedings{10.5555/1787553.1787577,
author = {Dig, Danny and Johnson, Ralph and Tip, Frank and De Moor, Oege and Becicka, Jan and Griswold, William G. and Keller, Markus},
title = {Refactoring Tools: Report on the 1st Workshop WRT at ECOOP 2007},
year = {2007},
isbn = {3540781943},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {WRT'07 was the first instance of the Workshop on Refactoring Tools. It was held in Berlin, Germany, on July 31st, in conjunction with ECOOP'07. The workshop brought together over 50 participants from both academia and industry. Participants include the lead developers of two widely used refactoring engines (Eclipse and NetBeans), researchers that work on refactoring tools and techniques, and others generally interested in refactoring. WRT'07 accepted 32 submissions, however, it was impossible to present all these submissions in one single day. Instead, in the morning session we started with a few technical presentations, followed by large group discussions around noon, a poster session and small group discussions in the afternoon. WRT'07 ended with a retrospective session and unanimous consensus to organize another session in the future.},
booktitle = {Proceedings of the 2007 Conference on Object-Oriented Technology},
pages = {193–202},
numpages = {10},
location = {Berlin, Germany},
series = {ECOOP'07}
}

@inproceedings{10.1109/ASE.2011.6100063,
author = {Yu, Yijun and Tun, Thein Than and Nuseibeh, Bashar},
title = {Specifying and Detecting Meaningful Changes in Programs},
year = {2011},
isbn = {9781457716386},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1109/ASE.2011.6100063},
doi = {10.1109/ASE.2011.6100063},
abstract = {Software developers are often interested in particular changes in programs that are relevant to their current tasks: not all changes to evolving software are equally important. However, most existing differencing tools, such as diff, notify developers of more changes than they wish to see. In this paper, we propose a technique to specify and automatically detect only those changes in programs deemed meaningful, or relevant, to a particular development task. Using four elementary annotations on the grammar of any programming language, namely Ignore, Order, Prefer and Scope, developers can specify, with limited effort, the type of change they wish to detect. Our algorithms use these annotations to transform the input programs into a normalised form, and to remove clones across different normalised programs in order to detect non-trivial and relevant differences. We evaluate our tool on a benchmark of programs to demonstrate its improved precision compared to other differencing approaches.},
booktitle = {Proceedings of the 2011 26th IEEE/ACM International Conference on Automated Software Engineering},
pages = {273–282},
numpages = {10},
series = {ASE '11}
}

@inproceedings{10.1145/3131704.3131715,
author = {Cheng, Yufeng and Wang, Meng and Xiong, Yingfei and Wu, Zhengkai and Wu, Yiming and Zhang, Lu},
title = {Un-Preprocessing: Extended CPP That Works with Your Tools},
year = {2017},
isbn = {9781450353137},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/3131704.3131715},
doi = {10.1145/3131704.3131715},
abstract = {Many tools directly change programs, such as bug-fixing tools, program migration tools, etc. We call them program-modification tools. On the other hand, many programming languages use the C preprocessor, such as C, C++, and Objective-C. Because of the complexity of preprocessors, many program-modification tools either fail to produce sound results under the presence of preprocessor directives, or give up completely and deal only with preprocessed code.In this paper we propose a lightweight approach that enables program-modification tools to work with the C preprocessor for free. The idea is that program-modification tools now simply target the preprocessed code, and our system, acting as a bidirectional C preprocessor, automatically propagates the changes on the preprocessed code back to the un-preprocessed code. The resulting source code is guaranteed to be correct and is kept similar to the original source as much as possible. We have evaluated our approach on Linux kernel with a set of generated changes. The evaluation results show the feasibility and effectiveness of our approach.},
booktitle = {Proceedings of the 9th Asia-Pacific Symposium on Internetware},
articleno = {3},
numpages = {10},
location = {Shanghai, China},
series = {Internetware'17}
}

@inproceedings{10.1145/2901739.2901762,
author = {Ahmad, Waqar and K\"{a}stner, Christian and Sunshine, Joshua and Aldrich, Jonathan},
title = {Inter-App Communication in Android: Developer Challenges},
year = {2016},
isbn = {9781450341868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/2901739.2901762},
doi = {10.1145/2901739.2901762},
abstract = {The Android platform is designed to support mutually untrusted third-party apps, which run as isolated processes but may interact via platform-controlled mechanisms, called Intents. Interactions among third-party apps are intended and can contribute to a rich user experience, for example, the ability to share pictures from one app with another. The Android platform presents an interesting point in a design space of module systems that is biased toward isolation, extensibility, and untrusted contributions. The Intent mechanism essentially provides message channels among modules, in which the set of message types is extensible. However, the module system has design limitations including the lack of consistent mechanisms to document message types, very limited checking that a message conforms to its specifications, the inability to explicitly declare dependencies on other modules, and the lack of checks for backward compatibility as message types evolve over time. In order to understand the degree to which these design limitations result in real issues, we studied a broad corpus of apps and cross-validated our results against app documentation and Android support forums. Our findings suggest that design limitations do indeed cause development problems. Based on our results, we outline further research questions and propose possible mitigation strategies.},
booktitle = {Proceedings of the 13th International Conference on Mining Software Repositories},
pages = {177–188},
numpages = {12},
location = {Austin, Texas},
series = {MSR '16}
}

@inproceedings{10.1145/3196398.3196449,
author = {Calciati, Paolo and Kuznetsov, Konstantin and Bai, Xue and Gorla, Alessandra},
title = {What Did Really Change with the New Release of the App?},
year = {2018},
isbn = {9781450357166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/3196398.3196449},
doi = {10.1145/3196398.3196449},
abstract = {The mobile app market is evolving at a very fast pace. In order to stay in the market and fulfill user's growing demands, developers have to continuously update their apps either to fix issues or to add new features. Users and market managers may have a hard time understanding what really changed in a new release though, and therefore may not make an informative guess of whether updating the app is recommendable, or whether it may pose new security and privacy threats for the user.We propose a ready-to-use framework to analyze the evolution of Android apps. Our framework extracts and visualizes various information ---such as how an app uses sensitive data, which third-party libraries it relies on, which URLs it connects to, etc.--- and combines it to create a comprehensive report on how the app evolved.Besides, we present the results of an empirical study on 235 applications with at least 50 releases using our framework. Our analysis reveals that Android apps tend to have more leaks of sensitive data over time, and that the majority of API calls relative to dangerous permissions are added to the code in releases posterior to the one where the corresponding permission was requested.},
booktitle = {Proceedings of the 15th International Conference on Mining Software Repositories},
pages = {142–152},
numpages = {11},
keywords = {app evolution, behavior change, Android},
location = {Gothenburg, Sweden},
series = {MSR '18}
}

@inproceedings{10.1145/3324884.3416618,
author = {Collie, Bruce and Ginsbach, Philip and Woodruff, Jackson and Rajan, Ajitha and O'Boyle, Michael F. P.},
title = {M<sup>3</sup>: Semantic API Migrations},
year = {2020},
isbn = {9781450367684},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/3324884.3416618},
doi = {10.1145/3324884.3416618},
abstract = {Library migration is a challenging problem, where most existing approaches rely on prior knowledge. This can be, for example, information derived from changelogs or statistical models of API usage.This paper addresses a different API migration scenario where there is no prior knowledge of the target library. We have no historical changelogs and no access to its internal representation. To tackle this problem, this paper proposes a novel approach (M3), where probabilistic program synthesis is used to semantically model the behavior of library functions. Then, we use an SMT-based code search engine to discover similar code in user applications. These discovered instances provide potential locations for API migrations.We evaluate our approach against 7 well-known libraries from varied application domains, learning correct implementations for 94 functions. Our approach is integrated with standard compiler tooling, and we use this integration to evaluate migration opportunities in 9 existing C/C++ applications with over 1MLoC. We discover over 7,000 instances of these functions, of which more than 2,000 represent migration opportunities.},
booktitle = {Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering},
pages = {90–102},
numpages = {13},
location = {Virtual Event, Australia},
series = {ASE '20}
}

@inproceedings{10.1145/2351676.2351727,
author = {Li, Huiqing and Thompson, Simon},
title = {Automated API Migration in a User-Extensible Refactoring Tool for Erlang Programs},
year = {2012},
isbn = {9781450312042},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/2351676.2351727},
doi = {10.1145/2351676.2351727},
abstract = { Wrangler is a refactoring and code inspection tool for Erlang programs. Apart from providing a set of built-in refactorings and code inspection functionalities, Wrangler allows users to define refactorings, code inspections, and general program transformations for themselves to suit their particular needs. These are defined using a template- and rule-based program transformation and analysis framework built into Wrangler.  This paper reports an extension to Wrangler's extension framework, supporting the automatic generation of API migration refactorings from a user-defined adapter module. },
booktitle = {Proceedings of the 27th IEEE/ACM International Conference on Automated Software Engineering},
pages = {294–297},
numpages = {4},
keywords = {Wrangler, refactoring, Erlang, template, rewrite rule, software engineering, API migration},
location = {Essen, Germany},
series = {ASE 2012}
}

@inproceedings{10.1145/2024445.2024463,
author = {Hata, Hideaki and Mizuno, Osamu and Kikuno, Tohru},
title = {Historage: Fine-Grained Version Control System for Java},
year = {2011},
isbn = {9781450308489},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/2024445.2024463},
doi = {10.1145/2024445.2024463},
abstract = {Software systems are changed continuously for adapting to the environment, correcting faults, improving performance, and so on. For in-depth analysis related to software evolution, it is informative to obtain the histories of fine-grained source code entities. This paper presents a tool named Historage that can provide entire histories of fine grained entities in Java, such as methods, constructors, fields, etc. A characteristic of Historage is the ability of tracing entity histories including renaming changes. We applied our technique to five open source software projects to quantitatively evaluate the renaming change identification.},
booktitle = {Proceedings of the 12th International Workshop on Principles of Software Evolution and the 7th Annual ERCIM Workshop on Software Evolution},
pages = {96–100},
numpages = {5},
keywords = {fine-grained version control, software evolution, fine-grained analysis, software repository},
location = {Szeged, Hungary},
series = {IWPSE-EVOL '11}
}

@inproceedings{10.1145/1858996.1859058,
author = {Lungu, Mircea and Robbes, Romain and Lanza, Michele},
title = {Recovering Inter-Project Dependencies in Software Ecosystems},
year = {2010},
isbn = {9781450301169},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/1858996.1859058},
doi = {10.1145/1858996.1859058},
abstract = {In large software systems, knowing the dependencies between modules or components is critical to assess the impact of changes. To recover the dependencies, fact extractors analyze the system as a whole and build the dependency graph, parsing the system down to the statement level. At the level of software ecosystems, which are collections of software projects, the dependencies that need to be recovered reside not only within the individual systems, but also between the libraries, frameworks, and entire software systems that make up the complete ecosystem; scaling issues arise.In this paper we present and evaluate several variants of a lightweight and scalable approach to recover dependencies between the software projects of an ecosystem. We evaluate our recovery algorithms on the Squeak 3.10 Universe, an ecosystem containing more than 200 software projects.},
booktitle = {Proceedings of the IEEE/ACM International Conference on Automated Software Engineering},
pages = {309–312},
numpages = {4},
keywords = {static analysis, software ecosystems, dependency analysis},
location = {Antwerp, Belgium},
series = {ASE '10}
}

@inproceedings{10.1145/2070821.2070828,
author = {Yu, Yijun and Bandara, Arosha and Tun, Thein Than and Nuseibeh, Bashar},
title = {Towards Learning to Detect Meaningful Changes in Software},
year = {2011},
isbn = {9781450310222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/2070821.2070828},
doi = {10.1145/2070821.2070828},
abstract = {Software developers are often concerned with particular changes that are relevant to their current tasks: not all changes to evolving software are equally important. Specified at the language-level, we have developed an automated technique to detect only those changes that are deemed meaningful, or relevant, to a particular development task [1]. In practice, however, it is realised that programmers are not always familiar with the production rules of a programming language. Rather, they may prefer to specify the meaningful changes using concrete program examples. In this position paper, we are proposing an inductive learning procedure that involves the programmers in constructing such language-level specifications through examples. Using the efficiently generated meaningful changes detector, programmers are presented with quicker feedback for adjusting the learnt specifications. An illustrative example is used to show how such an inductive learning procedure might be applied.},
booktitle = {Proceedings of the International Workshop on Machine Learning Technologies in Software Engineering},
pages = {51–54},
numpages = {4},
location = {Lawrence, Kansas, USA},
series = {MALETS '11}
}

@inproceedings{10.1145/3194793.3194798,
author = {Gerasimou, Simos and Kechagia, Maria and Kolovos, Dimitris and Paige, Richard and Gousios, Georgios},
title = {On Software Modernisation Due to Library Obsolescence},
year = {2018},
isbn = {9781450357548},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/3194793.3194798},
doi = {10.1145/3194793.3194798},
abstract = {Software libraries, typically accessible through Application Programming Interfaces (APIs), enhance modularity and reduce development time. Nevertheless, their use reinforces system dependency on third-party software. When libraries become obsolete or their APIs change, performing the necessary modifications to dependent systems, can be time-consuming, labour intensive and error-prone. In this paper, we propose a methodology that reduces the effort developers must spend to mitigate library obsolescence. We describe the steps comprising the methodology, i.e., source code analysis, visualisation of hot areas, code-based transformation, and verification of the modified system. Also, we present some preliminary results and describe our plan for developing a fully automated software modernisation approach.},
booktitle = {Proceedings of the 2nd International Workshop on API Usage and Evolution},
pages = {6–9},
numpages = {4},
keywords = {software modernisation, visualisation, software libraries, library evolution, application programming interfaces},
location = {Gothenburg, Sweden},
series = {WAPI '18}
}

@inproceedings{10.1145/1851276.1851279,
author = {FitzRoy-Dale, Nicholas and Kuz, Ihor and Heiser, Gernot},
title = {Architecture Optimisation with Currawong},
year = {2010},
isbn = {9781450301954},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/1851276.1851279},
doi = {10.1145/1851276.1851279},
abstract = {We describe Currawong, a tool to perform system software architecture optimisation. Currawong is an extensible tool which applies optimisations at the point where an application invokes framework or library code. Currawong does not require source code to perform optimisations, effectively decoupling the relationship between compilation and optimisation. We show, through examples written for the popular Android smartphone platform, that Currawong is capable of significant performance improvement to existing applications.},
booktitle = {Proceedings of the First ACM Asia-Pacific Workshop on Workshop on Systems},
pages = {7–12},
numpages = {6},
keywords = {binary rewriting, optimization, android, optimisation, prolog},
location = {New Delhi, India},
series = {APSys '10}
}

@inproceedings{10.5555/3106028.3106035,
author = {Juchli, Marc and Krombeen, Lars and Rao, Shashank and Yu, Chak Shun and Sawant, Anand Ashok and Bacchelli, Alberto},
title = {Mining Motivated Trends of Usage of Haskell Libraries},
year = {2017},
isbn = {9781538628058S},
publisher = {IEEE Press},
abstract = {We propose an initial approach to mine the usage trends of libraries in Haskell, a popular functional programming language. We integrate it with a novel, initial method to automatically determine the reasons of clients for switching to different versions. Based on these, we conduct a preliminary investigation of trends of usage in Haskell libraries. Results suggest that trends are similar to those in the Java ecosystem and in line with Rogers theory on the diffusion of innovation. Our results also provide indication on Haskell libraries being all by and large stable.},
booktitle = {Proceedings of the 1st International Workshop on API Usage and Evolution},
pages = {11–14},
numpages = {4},
location = {Buenos Aires, Argentina},
series = {WAPI '17}
}

@inproceedings{10.1145/3238147.3238181,
author = {Huang, Huaxun and Wei, Lili and Liu, Yepang and Cheung, Shing-Chi},
title = {Understanding and Detecting Callback Compatibility Issues for Android Applications},
year = {2018},
isbn = {9781450359375},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/3238147.3238181},
doi = {10.1145/3238147.3238181},
abstract = {The control flows of Android apps are largely driven by the protocols that govern how callback APIs are invoked in response to various events. When these callback APIs evolve along with the Android framework, the changes in their invocation protocols can induce unexpected control flows to existing Android apps, causing various compatibility issues. We refer to these issues as callback compatibility issues. While Android framework updates have received due attention, little is known about their impacts on app control flows and the callback compatibility issues thus induced. To bridge the gap, we examined Android documentations and conducted an empirical study on 100 real-world callback compatibility issues to investigate how these issues were induced by callback API evolutions. Based on our empirical findings, we propose a graph-based model to capture the control flow inconsistencies caused by API evolutions and devise a static analysis technique, Cider, to detect callback compatibility issues. Our evaluation of Cider&nbsp;on 20 popular open-source Android apps shows that Cider&nbsp;is effective. It detected 13 new callback compatibility issues in these apps, among which 12 issues were confirmed and 9 issues were fixed.},
booktitle = {Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering},
pages = {532–542},
numpages = {11},
keywords = {Android API, callback compatibility, static analysis, empirical study},
location = {Montpellier, France},
series = {ASE 2018}
}

@inproceedings{10.1145/1449764.1449788,
author = {Tansey, Wesley and Tilevich, Eli},
title = {Annotation Refactoring: Inferring Upgrade Transformations for Legacy Applications},
year = {2008},
isbn = {9781605582153},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/1449764.1449788},
doi = {10.1145/1449764.1449788},
abstract = {Since annotations were added to the Java language, many frameworks have moved to using annotated Plain Old Java Objects (POJOs) in their newest releases. Legacy applications are thus forced to undergo extensive restructuring in order to migrate from old framework versions to new versions based on annotations (Version Lock-in). Additionally, because annotations are embedded in the application code, changing between framework vendors may also entail largescale manual changes (Vendor Lock-in).This paper presents a novel refactoring approach that effectively solves these two problems. Our approach infers a concise set of semantics-preserving transformation rules from two versions of a single class. Unlike prior approaches that detect only simple structural refactorings, our algorithm can infer general composite refactorings and is more than 97% accurate on average. We demonstrate the effectiveness of our approach by automatically upgrading more than 80K lines of the unit testing code of four open-source Java applications to use the latest version of the popular JUnit testing framework.},
booktitle = {Proceedings of the 23rd ACM SIGPLAN Conference on Object-Oriented Programming Systems Languages and Applications},
pages = {295–312},
numpages = {18},
keywords = {eclipse, annotations, java, frameworks, upgrading, refactoring, metadata, JUnit},
location = {Nashville, TN, USA},
series = {OOPSLA '08}
}

@article{10.1145/1449955.1449788,
author = {Tansey, Wesley and Tilevich, Eli},
title = {Annotation Refactoring: Inferring Upgrade Transformations for Legacy Applications},
year = {2008},
issue_date = {September 2008},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {10},
issn = {0362-1340},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/1449955.1449788},
doi = {10.1145/1449955.1449788},
abstract = {Since annotations were added to the Java language, many frameworks have moved to using annotated Plain Old Java Objects (POJOs) in their newest releases. Legacy applications are thus forced to undergo extensive restructuring in order to migrate from old framework versions to new versions based on annotations (Version Lock-in). Additionally, because annotations are embedded in the application code, changing between framework vendors may also entail largescale manual changes (Vendor Lock-in).This paper presents a novel refactoring approach that effectively solves these two problems. Our approach infers a concise set of semantics-preserving transformation rules from two versions of a single class. Unlike prior approaches that detect only simple structural refactorings, our algorithm can infer general composite refactorings and is more than 97% accurate on average. We demonstrate the effectiveness of our approach by automatically upgrading more than 80K lines of the unit testing code of four open-source Java applications to use the latest version of the popular JUnit testing framework.},
journal = {SIGPLAN Not.},
month = oct,
pages = {295–312},
numpages = {18},
keywords = {JUnit, eclipse, upgrading, frameworks, java, metadata, refactoring, annotations}
}

@inproceedings{10.1145/3180155.3180170,
author = {Sawant, Anand Ashok and Aniche, Maur\'{\i}cio and van Deursen, Arie and Bacchelli, Alberto},
title = {Understanding Developers' Needs on Deprecation as a Language Feature},
year = {2018},
isbn = {9781450356381},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/3180155.3180170},
doi = {10.1145/3180155.3180170},
abstract = {Deprecation is a language feature that allows API producers to mark a feature as obsolete. We aim to gain a deep understanding of the needs of API producers and consumers alike regarding deprecation. To that end, we investigate why API producers deprecate features, whether they remove deprecated features, how they expect consumers to react, and what prompts an API consumer to react to deprecation. To achieve this goal we conduct semi-structured interviews with 17 third-party Java API producers and survey 170 Java developers. We observe that the current deprecation mechanism in Java and the proposal to enhance it does not address all the needs of a developer. This leads us to propose and evaluate three further enhancements to the deprecation mechanism.},
booktitle = {Proceedings of the 40th International Conference on Software Engineering},
pages = {561–571},
numpages = {11},
keywords = {deprecation, Java, API},
location = {Gothenburg, Sweden},
series = {ICSE '18}
}

@inproceedings{10.1145/3106195.3106203,
author = {Seidl, Christoph and Berger, Thorsten and Elsner, Christoph and Schultis, Klaus-Benedikt},
title = {Challenges and Solutions for Opening Small and Medium-Scale Industrial Software Platforms},
year = {2017},
isbn = {9781450352215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/3106195.3106203},
doi = {10.1145/3106195.3106203},
abstract = {Establishing open software platforms is becoming increasingly important. Many vendors of large and well-known open platforms, such as Android or iOS, have successfully established huge ecosystems of platform extensions (apps). While such platforms are important role models, the practices and technologies employed by their vendors are often not applicable for smaller platform vendors, who have different goals and carry substantial legacy, such as an existing closed platform. Yet, many vendors start to open their platforms---for instance, when they alone cannot realize all incoming requirements anymore. Unfortunately, very few best practices exist to guide this opening process, especially for small and medium-scale industrial platforms with their specific solutions. We present a study of industrial organizations that successfully opened closed platforms. Using a survey, we identified 18 opened platforms, providing a broad picture, which is complemented with in-depth, qualitative insights from a case study of three organizations. We elicited the platforms' core characteristics, the organizations' opening strategies, as well as challenges and solutions. We believe that our results support practitioners seeking to open platforms, and researchers striving to build better methods and tools.},
booktitle = {Proceedings of the 21st International Systems and Software Product Line Conference - Volume A},
pages = {153–162},
numpages = {10},
location = {Sevilla, Spain},
series = {SPLC '17}
}

@article{10.1145/3038926,
author = {Soetens, Quinten David and Robbes, Romain and Demeyer, Serge},
title = {Changes as First-Class Citizens: A Research Perspective on Modern Software Tooling},
year = {2017},
issue_date = {June 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {2},
issn = {0360-0300},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/3038926},
doi = {10.1145/3038926},
abstract = {Software must evolve to keep up with an ever-changing context, the real world. We discuss an emergent trend in software evolution research revolving around the central notion that drives evolution: Change. By reifying change, and by modelling it as a first-class entity, researchers can now analyse the complex phenomenon known as software evolution with an unprecedented degree of accuracy. We present a Systematic Mapping Study of 86 articles to give an overview on the state of the art in this area of research and present a roadmap with open issues and future directions.},
journal = {ACM Comput. Surv.},
month = apr,
articleno = {18},
numpages = {38},
keywords = {change recording, Systematic mapping study, fine-grained changes, atomic change operations, change distilling, fine-grained edit operations}
}

@inproceedings{10.1145/3092703.3098230,
author = {Casalnuovo, Casey and Suchak, Yagnik and Ray, Baishakhi and Rubio-Gonz\'{a}lez, Cindy},
title = {GitcProc: A Tool for Processing and Classifying GitHub Commits},
year = {2017},
isbn = {9781450350761},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/3092703.3098230},
doi = {10.1145/3092703.3098230},
abstract = { Sites such as GitHub have created a vast collection of software artifacts that researchers interested in understanding and improving software systems can use. Current tools for processing such GitHub data tend to target project metadata and avoid source code processing, or process source code in a manner that requires significant effort for each language supported. This paper presents GitcProc, a lightweight tool based on regular expressions and source code blocks, which downloads projects and extracts their project history, including fine-grained source code information and development time bug fixes. GitcProc can track changes to both single-line and block source code structures and associate these changes to the surrounding function context with minimal set up required from users. We demonstrate GitcProc's ability to capture changes in multiple languages by evaluating it on C, C++, Java, and Python projects, and show it finds bug fixes and the context of source code changes effectively with few false positives. },
booktitle = {Proceedings of the 26th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {396–399},
numpages = {4},
keywords = {Git Mining Tool, Information Extraction, Language Independence},
location = {Santa Barbara, CA, USA},
series = {ISSTA 2017}
}

@inproceedings{10.1145/2950290.2983955,
author = {Zhang, Hongyu and Jain, Anuj and Khandelwal, Gaurav and Kaushik, Chandrashekhar and Ge, Scott and Hu, Wenxiang},
title = {Bing Developer Assistant: Improving Developer Productivity by Recommending Sample Code},
year = {2016},
isbn = {9781450342186},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/2950290.2983955},
doi = {10.1145/2950290.2983955},
abstract = { In programming practice, developers often need sample code in order to learn how to solve a programming-related problem. For example, how to reuse an Application Programming Interface (API) of a large-scale software library and how to implement a certain functionality. We believe that previously written code can help developers understand how others addressed the similar problems and can help them write new programs. We develop a tool called Bing Developer Assistant (BDA), which improves developer productivity by recommending sample code mined from public software repositories (such as GitHub) and web pages (such as Stack Overflow). BDA can automatically mine code snippets that implement an API or answer a code search query. It has been implemented as a free-downloadable extension of Microsoft Visual Studio and has received more than 670K downloads since its initial release in December 2014. BDA is publicly available at: http://aka.ms/devassistant. },
booktitle = {Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering},
pages = {956–961},
numpages = {6},
keywords = {Code Search, API, GitHub, Software Reuse, API Usage Extraction},
location = {Seattle, WA, USA},
series = {FSE 2016}
}

@article{10.1145/1925861.1925880,
author = {FitzRoy-Dale, Nicholas and Kuz, Ihor and Heiser, Gernot},
title = {Architecture Optimisation with Currawong},
year = {2011},
issue_date = {January 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {41},
number = {1},
issn = {0146-4833},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/1925861.1925880},
doi = {10.1145/1925861.1925880},
abstract = {We describe Currawong, a tool to perform system software architecture optimisation. Currawong is an extensible tool which applies optimisations at the point where an application invokes framework or library code. Currawong does not require source code to perform optimisations, effectively decoupling the relationship between compilation and optimisation. We show, through examples written for the popular Android smartphone platform, that Currawong is capable of significant performance improvement to existing applications.},
journal = {SIGCOMM Comput. Commun. Rev.},
month = jan,
pages = {115–119},
numpages = {5},
keywords = {optimization, binary rewriting, optimisation, prolog, android}
}

@inproceedings{10.1145/2642803.2642815,
author = {Haenni, Nicole and Lungu, Mircea and Schwarz, Niko and Nierstrasz, Oscar},
title = {A Quantitative Analysis of Developer Information Needs in Software Ecosystems},
year = {2014},
isbn = {9781450327787},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/2642803.2642815},
doi = {10.1145/2642803.2642815},
abstract = {We present the results of an investigation into the nature of information needs of software developers who work in projects that are part of larger ecosystems. This work is based on a quantitative survey of 75 professional software developers. We corroborate the results identified in the survey with needs and motivations proposed in a previous survey and discover that tool support for developers working in an ecosystem context is even more meager than we thought: mailing lists and internet search are the most popular tools developers use to satisfy their ecosystem-related information needs.},
booktitle = {Proceedings of the 2014 European Conference on Software Architecture Workshops},
articleno = {12},
numpages = {6},
keywords = {program comprehension, open source software, frameworks and libraries, programmer needs, Software ecosystems},
location = {Vienna, Austria},
series = {ECSAW '14}
}

@inproceedings{10.1109/ASE.2013.6693119,
author = {Holder, Ethan and Shah, Eeshan and Davoodi, Mohammed and Tilevich, Eli},
title = {Cloud Twin: Native Execution of Android Applications on the Windows Phone},
year = {2013},
isbn = {9781479902156},
publisher = {IEEE Press},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1109/ASE.2013.6693119},
doi = {10.1109/ASE.2013.6693119},
abstract = {To successfully compete in the software marketplace, modern mobile applications must run on multiple competing platforms, such as Android, iOS, and Windows Phone. Companies producing mobile applications spend substantial amounts of time, effort, and money to port applications across platforms. Creating individual program versions for different platforms further exacerbates the maintenance burden. This paper presents Cloud Twin, a novel approach to natively executing the functionality of a mobile application written for another platform. The functionality is accessed by means of dynamic cross-platform replay, in which the source application's execution in the cloud is mimicked natively on the target platform. The reference implementation of Cloud Twin natively emulates the behavior of Android applications on a Windows Phone. Specifically, Cloud Twin transmits, via web sockets, the UI actions performed on the Windows Phone to the cloud server, which then mimics the received actions on the Android emulator. The UI updates on the emulator are efficiently captured by means of Aspect Oriented Programming and sent back to be replayed on the Windows Phone. Our case studies with third-party applications indicate that the Cloud Twin approach can become a viable solution to the heterogeneity of the mobile application market.},
booktitle = {Proceedings of the 28th IEEE/ACM International Conference on Automated Software Engineering},
pages = {598–603},
numpages = {6},
location = {Silicon Valley, CA, USA},
series = {ASE'13}
}

@inproceedings{10.1145/2797433.2797478,
author = {Alami, Daniel and Rodr\'{\i}guez, Mar\'{\i}a and Jansen, Slinger},
title = {Relating Health to Platform Success: Exploring Three E-Commerce Ecosystems},
year = {2015},
isbn = {9781450333931},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/2797433.2797478},
doi = {10.1145/2797433.2797478},
abstract = {The market for e-commerce systems is saturated with more than 60 different solutions that compete and try to accommodate different needs. However, it appears that three main platforms account for roughly half of the market share: Magento, PrestaShop, and WooCommerce. This paper evaluates these platforms from a software ecosystems health perspective. By shedding light on the success factors of these ecosystems, we aim at establishing what makes an e-commerce ecosystem healthy. This knowledge provides ecosystem orchestrators with an overview of the current health of these ecosystems, and researchers with an application of ecosystem health assessment.},
booktitle = {Proceedings of the 2015 European Conference on Software Architecture Workshops},
articleno = {43},
numpages = {6},
keywords = {Magento, e-Commerce Platform, Health Assessment, Software Ecosystem, WooCommerce, PrestaShop},
location = {Dubrovnik, Cavtat, Croatia},
series = {ECSAW '15}
}

@inproceedings{10.1145/3196398.3196419,
author = {Li, Li and Gao, Jun and Bissyand\'{e}, Tegawend\'{e} F. and Ma, Lei and Xia, Xin and Klein, Jacques},
title = {Characterising Deprecated Android APIs},
year = {2018},
isbn = {9781450357166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/3196398.3196419},
doi = {10.1145/3196398.3196419},
abstract = {Because of functionality evolution, or security and performance-related changes, some APIs eventually become unnecessary in a software system and thus need to be cleaned to ensure proper maintainability. Those APIs are typically marked first as deprecated APIs and, as recommended, follow through a deprecated-replaceremove cycle, giving an opportunity to client application developers to smoothly adapt their code in next updates. Such a mechanism is adopted in the Android framework development where thousands of reusable APIs are made available to Android app developers.In this work, we present a research-based prototype tool called CDA and apply it to different revisions (i.e., releases or tags) of the Android framework code for characterising deprecated APIs. Based on the data mined by CDA, we then perform an exploratory study on API deprecation in the Android ecosystem and the associated challenges for maintaining quality apps. In particular, we investigate the prevalence of deprecated APIs, their annotations and documentation, their removal and consequences, their replacement messages, as well as developer reactions to API deprecation. Experimental results reveal several findings that further provide promising insights for future research directions related to deprecated Android APIs. Notably, by mining the source code of the Android framework base, we have identified three bugs related to deprecated APIs. These bugs have been quickly assigned and positively appreciated by the framework maintainers, who claim that these issues will be updated in future releases.},
booktitle = {Proceedings of the 15th International Conference on Mining Software Repositories},
pages = {254–264},
numpages = {11},
location = {Gothenburg, Sweden},
series = {MSR '18}
}

@article{10.1145/1108768.1108769,
author = {ACM SIGSOFT Software Engineering Notes staff},
title = {Frontmatter (TOC, Letter from the Chair, Letter from the Editor, Letters to the Editor, ACM Policy and Procedures on Plagiarism, PASTE Abstracts, Calendar of Future Events, Workshop and Conference Information)},
year = {2006},
issue_date = {January 2006},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {1},
issn = {0163-5948},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/1108768.1108769},
doi = {10.1145/1108768.1108769},
journal = {SIGSOFT Softw. Eng. Notes},
month = jan,
pages = {0},
numpages = {18}
}

@inproceedings{10.1145/1984732.1984734,
author = {Abadi, Aharon and Feldman, Yishai A. and Shomrat, Mati},
title = {Code-Motion for API Migration: Fixing SQL Injection Vulnerabilities in Java},
year = {2011},
isbn = {9781450305792},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/1984732.1984734},
doi = {10.1145/1984732.1984734},
abstract = {Refactoring often requires the reordering of code fragments; such is the case when migrating from one API to another. Performing such reordering manually is complex and error-prone. A specific example in the security domain involves database query execution, in which some of the parameters come from untrusted sources. In Java, the Statement API provides opportunities for SQL injection attacks. The recommended remedy is to replace it with the secure Prepared-Statement API; however, that sometimes requires changing the order in which the query is built. We present an algorithm that performs this migration, moving code as necessary to preserve functionality while changing the structure of the original code as little as possible.},
booktitle = {Proceedings of the 4th Workshop on Refactoring Tools},
pages = {1–7},
numpages = {7},
keywords = {sql injection, refactoring, api migration},
location = {Waikiki, Honolulu, HI, USA},
series = {WRT '11}
}

@inproceedings{10.1109/MiSE.2019.00018,
author = {Sch\"{o}ttle, Matthias and Kienzle, J\"{o}rg},
title = {On the Difficulties of Raising the Level of Abstraction and Facilitating Reuse in Software Modelling: The Case for Signature Extension},
year = {2019},
publisher = {IEEE Press},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1109/MiSE.2019.00018},
doi = {10.1109/MiSE.2019.00018},
abstract = {Reuse is central to improving the software development process, increasing software quality and decreasing time-to-market. Hence it is of paramount importance that modelling languages provide features that enable the specification and modularization of reusable artefacts, as well as their subsequent reuse. In this paper we outline several difficulties caused by the finality of method signatures that make it hard to specify and use reusable artefacts encapsulating several variants. The difficulties are illustrated with a running example. To evaluate whether these difficulties can be observed at the programming level, we report on an empirical study conducted on the Java Platform API as well as present workarounds used in various programming languages to deal with the rigid nature of signatures. Finally, we outline signature extension as an approach to overcome these problems at the modelling level.},
booktitle = {Proceedings of the 11th International Workshop on Modelling in Software Engineerings},
pages = {71–77},
numpages = {7},
location = {Montreal, Quebec, Canada},
series = {MiSE '19}
}

@inproceedings{10.1145/1985793.1985815,
author = {Kim, Miryung and Cai, Dongxiang and Kim, Sunghun},
title = {An Empirical Investigation into the Role of API-Level Refactorings during Software Evolution},
year = {2011},
isbn = {9781450304450},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/1985793.1985815},
doi = {10.1145/1985793.1985815},
abstract = {It is widely believed that refactoring improves software quality and programmer productivity by making it easier to maintain and understand software systems. However, the role of refactorings has not been systematically investigated using fine-grained evolution history. We quantitatively and qualitatively studied API-level refactorings and bug fixes in three large open source projects, totaling 26523 revisions of evolution.The study found several surprising results: One, there is an increase in the number of bug fixes after API-level refactorings. Two, the time taken to fix bugs is shorter after API-level refactorings than before. Three, a large number of refactoring revisions include bug fixes at the same time or are related to later bug fix revisions. Four, API-level refactorings occur more frequently before than after major software releases. These results call for re-thinking refactoring's true benefits. Furthermore, frequent floss refactoring mistakes observed in this study call for new software engineering tools to support safe application of refactoring and behavior modifying edits together.},
booktitle = {Proceedings of the 33rd International Conference on Software Engineering},
pages = {151–160},
numpages = {10},
keywords = {software evolution, defects, release cycle, empirical study, refactoring},
location = {Waikiki, Honolulu, HI, USA},
series = {ICSE '11}
}

@article{10.1145/2000799.2000805,
author = {Dagenais, Barth\'{e}l\'{e}my and Robillard, Martin P.},
title = {Recommending Adaptive Changes for Framework Evolution},
year = {2011},
issue_date = {September 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {20},
number = {4},
issn = {1049-331X},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/2000799.2000805},
doi = {10.1145/2000799.2000805},
abstract = {In the course of a framework’s evolution, changes ranging from a simple refactoring to a complete rearchitecture can break client programs. Finding suitable replacements for framework elements that were accessed by a client program and deleted as part of the framework’s evolution can be a challenging task. We present a recommendation system, SemDiff, that suggests adaptations to client programs by analyzing how a framework was adapted to its own changes. In a study of the evolution of one open source framework and three client programs, our approach recommended relevant adaptive changes with a high level of precision. In a second study of the evolution of two frameworks, we found that related change detection approaches were better at discovering systematic changes and that SemDiff was complementary to these approaches by detecting non-trivial changes such as when a functionality is imported from an external library.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = sep,
articleno = {19},
numpages = {35},
keywords = {mining software repositories, software evolution, origin analysis, partial program analysis, recommendation system, Adaptive changes, framework, legacy study}
}

@inproceedings{10.1109/MSR.2019.00062,
author = {Matos, Anderson S. and Filho, Jo\~{a}o B. Ferreira and Rocha, Lincoln S.},
title = {Splitting APIs: An Exploratory Study of Software Unbundling},
year = {2019},
publisher = {IEEE Press},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1109/MSR.2019.00062},
doi = {10.1109/MSR.2019.00062},
abstract = {Software unbundling consists of dividing an existing software artifact into smaller ones. Unbundling can be useful for removing clutter from the original application or separating different features that may not share the same purpose, or simply for isolating an emergent functionality that merits to be an application on its own. This phenomenon is frequent with mobile apps and it is also propagating to APIs. This paper proposes a first empirical study on unbundling to understand its effects on popular APIs. We explore the possibilities of splitting libraries into 2 or more bundles based on the use that their client projects make of them. We mine over than 71,000 client projects of 10 open source APIs and automatically generate 2,090 sub-APIs to then study their properties. We find that it is possible to have sets of different ways of using a given API and to unbundle it accordingly; the bundles can vary their representativeness and uniqueness, which is analyzed thoroughly in this study.},
booktitle = {Proceedings of the 16th International Conference on Mining Software Repositories},
pages = {360–370},
numpages = {11},
keywords = {api usage, mining software repositories, exploratory study, software unbundling, modularity},
location = {Montreal, Quebec, Canada},
series = {MSR '19}
}

@inproceedings{10.1109/ICSE.2007.20,
author = {Kim, Miryung and Notkin, David and Grossman, Dan},
title = {Automatic Inference of Structural Changes for Matching across Program Versions},
year = {2007},
isbn = {0769528287},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1109/ICSE.2007.20},
doi = {10.1109/ICSE.2007.20},
abstract = {Mapping code elements in one version of a program to corresponding code elements in another version is a fundamental building block for many software engineering tools. Existing tools that match code elements or identify structural changes--refactorings and API changes--between two versions of a program have two limitations that we overcome. First, existing tools cannot easily disambiguate among many potential matches or refactoring candidates. Second, it is difficult to use these tools' results for various software engineering tasks due to an unstructured representation of results. To overcome these limitations, our approach represents structural changes as a set of high-level change rules, automatically infers likely change rules and determines method-level matches based on the rules. By applying our tool to several open source projects, we show that our tool identifies matches that are difficult to find using other approaches and produces more concise results than other approaches. Our representation can serve as a better basis for other software engineering tools.},
booktitle = {Proceedings of the 29th International Conference on Software Engineering},
pages = {333–343},
numpages = {11},
series = {ICSE '07}
}

@inproceedings{10.1145/3379597.3387476,
author = {Mujahid, Suhaib and Abdalkareem, Rabe and Shihab, Emad and McIntosh, Shane},
title = {Using Others' Tests to Identify Breaking Updates},
year = {2020},
isbn = {9781450375177},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/3379597.3387476},
doi = {10.1145/3379597.3387476},
abstract = {The reuse of third-party packages has become a common practice in contemporary software development. Software dependencies are constantly evolving with newly added features and patches that fix bugs in older versions. However, updating dependencies could introduce new bugs or break backward compatibility. In this work, we propose a technique to detect breakage-inducing versions of third-party dependencies. The key insight behind our approach is to leverage the automated test suites of other projects that depend upon the same dependency to test newly released versions. We conjecture that this crowd-based approach will help to detect breakage-inducing versions because it broadens the set of realistic usage scenarios to which a package version has been exposed. To evaluate our conjecture, we perform an empirical study of 391,553 npm packages. We use the dependency network from these packages to identify candidate tests of third-party packages. Moreover, to evaluate our proposed technique, we mine the history of this dependency network to identify ten breakage-inducing versions. We find that our proposed technique can detect six of the ten studied breakage-inducing versions. Our findings can help developers to make more informed decisions when they update their dependencies.},
booktitle = {Proceedings of the 17th International Conference on Mining Software Repositories},
pages = {466–476},
numpages = {11},
keywords = {Empirical Studies, Software Testing, Software Ecosystems, JavaScript, Software Quality, Node.js},
location = {Seoul, Republic of Korea},
series = {MSR '20}
}

@inproceedings{10.1109/ICPC.2017.30,
author = {Zampetti, Fiorella and Ponzanelli, Luca and Bavota, Gabriele and Mocci, Andrea and Di Penta, Massimiliano and Lanza, Michele},
title = {How Developers Document Pull Requests with External References},
year = {2017},
isbn = {9781538605356},
publisher = {IEEE Press},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1109/ICPC.2017.30},
doi = {10.1109/ICPC.2017.30},
abstract = {Online resources of formal and informal documentation-such as reference manuals, forum discussions and tutorials-have become an asset to software developers, as they allow them to tackle problems and to learn about new tools, libraries, and technologies. This study investigates to what extent and for which purpose developers refer to external online resources when they contribute changes to a repository by raising a pull request. Our study involved (i) a quantitative analysis of over 150k URLs occurring in pull requests posted in GitHub; (ii) a manual coding of the kinds of software evolution activities performed in commits related to a statistically significant sample of 2,130 pull requests referencing external documentation resources; (iii) a survey with 69 participants, who provided feedback on how they use online resources and how they refer to them when filing a pull request. Results of the study indicate that, on the one hand, developers find external resources useful to learn something new or to solve specific problems, and they perceive useful referring such resources to better document changes. On the other hand, both interviews and repository mining suggest that external resources are still rarely referred in document changes.},
booktitle = {Proceedings of the 25th International Conference on Program Comprehension},
pages = {23–33},
numpages = {11},
keywords = {online resources, documenting changes, empirical study},
location = {Buenos Aires, Argentina},
series = {ICPC '17}
}

@inproceedings{10.1145/2393596.2393655,
author = {Kim, Miryung and Zimmermann, Thomas and Nagappan, Nachiappan},
title = {A Field Study of Refactoring Challenges and Benefits},
year = {2012},
isbn = {9781450316149},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/2393596.2393655},
doi = {10.1145/2393596.2393655},
abstract = {It is widely believed that refactoring improves software quality and developer productivity. However, few empirical studies quantitatively assess refactoring benefits or investigate developers' perception towards these benefits. This paper presents a field study of refactoring benefits and challenges at Microsoft through three complementary study methods: a survey, semi-structured interviews with professional software engineers, and quantitative analysis of version history data. Our survey finds that the refactoring definition in practice is not confined to a rigorous definition of semantics-preserving code transformations and that developers perceive that refactoring involves substantial cost and risks. We also report on interviews with a designated refactoring team that has led a multi-year, centralized effort on refactoring Windows. The quantitative analysis of Windows 7 version history finds that the binary modules refactored by this team experienced significant reduction in the number of inter-module dependencies and post-release defects, indicating a visible benefit of refactoring.},
booktitle = {Proceedings of the ACM SIGSOFT 20th International Symposium on the Foundations of Software Engineering},
articleno = {50},
numpages = {11},
keywords = {component dependencies, refactoring, churn, empirical study, software evolution, defects},
location = {Cary, North Carolina},
series = {FSE '12}
}

@inproceedings{10.1145/3196398.3196420,
author = {Lamothe, Maxime and Shang, Weiyi},
title = {Exploring the Use of Automated API Migrating Techniques in Practice: An Experience Report on Android},
year = {2018},
isbn = {9781450357166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/3196398.3196420},
doi = {10.1145/3196398.3196420},
abstract = {In recent years, open source software libraries have allowed developers to build robust applications by consuming freely available application program interfaces (API). However, when these APIs evolve, consumers are left with the difficult task of migration. Studies on API migration often assume that software documentation lacks explicit information for migration guidance and is impractical for API consumers. Past research has shown that it is possible to present migration suggestions based on historical code-change information. On the other hand, research approaches with optimistic views of documentation have also observed positive results. Yet, the assumptions made by prior approaches have not been evaluated on large scale practical systems, leading to a need to affirm their validity. This paper reports our recent practical experience migrating the use of Android APIs in FDroid apps when leveraging approaches based on documentation and historical code changes. Our experiences suggest that migration through historical codechanges presents various challenges and that API documentation is undervalued. In particular, the majority of migrations from removed or deprecated Android APIs to newly added APIs can be suggested by a simple keyword search in the documentation. More importantly, during our practice, we experienced that the challenges of API migration lie beyond migration suggestions, in aspects such as coping with parameter type changes in new API. Future research may aim to design automated approaches to address the challenges that are documented in this experience report.},
booktitle = {Proceedings of the 15th International Conference on Mining Software Repositories},
pages = {503–514},
numpages = {12},
keywords = {API migration, software evolution, Android API, mining software repositories},
location = {Gothenburg, Sweden},
series = {MSR '18}
}

@inproceedings{10.1145/1831708.1831723,
author = {Gruska, Natalie and Wasylkowski, Andrzej and Zeller, Andreas},
title = {Learning from 6,000 Projects: Lightweight Cross-Project Anomaly Detection},
year = {2010},
isbn = {9781605588230},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/1831708.1831723},
doi = {10.1145/1831708.1831723},
abstract = {Real production code contains lots of knowledge - on the domain, on the architecture, and on the environment. How can we leverage this knowledge in new projects? Using a novel lightweight source code parser, we have mined more than 6,000 open source Linux projects (totaling 200,000,000 lines of code) to obtain 16,000,000 temporal properties reflecting normal interface usage. New projects can be checked against these rules to detect anomalies - that is, code that deviates from the wisdom of the crowds. In a sample of 20 projects, ~25% of the top-ranked anomalies uncovered actual code smells or defects.},
booktitle = {Proceedings of the 19th International Symposium on Software Testing and Analysis},
pages = {119–130},
numpages = {12},
keywords = {formal concept analysis, temporal properties, language independent parsing, lightweight parsing, mining specifications},
location = {Trento, Italy},
series = {ISSTA '10}
}

@inproceedings{10.1145/2660460.2660471,
author = {Robinson, Nicky and Bonneau, Joseph},
title = {Cognitive Disconnect: Understanding Facebook Connect Login Permissions},
year = {2014},
isbn = {9781450331982},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/2660460.2660471},
doi = {10.1145/2660460.2660471},
abstract = {We study Facebook Connect's permissions system using crawling, experimentation, and user surveys. We find several areas in which it it works differently than many users and developers expect. More permissions can be granted than developers intend. In particular, permissions that allow a site to post to the user's profile are granted on an all-or-nothing basis. While users generally understand what data sites can read from their profile, they generally do not understand the full extent of what sites can post. In the case of write permissions, we show that user expectations are influenced by the identity of the requesting site although this has no impact on what is actually enforced. We also find that users generally do not understand the way Facebook Connect permissions interact with Facebook's privacy settings. Our results suggest that users understand detailed, granular messages better than those that are broad and vague.},
booktitle = {Proceedings of the Second ACM Conference on Online Social Networks},
pages = {247–258},
numpages = {12},
keywords = {privacy, facebook, online social networks, permissions},
location = {Dublin, Ireland},
series = {COSN '14}
}

@inproceedings{10.1145/2597073.2597109,
author = {Linares-V\'{a}squez, Mario and Holtzhauer, Andrew and Bernal-C\'{a}rdenas, Carlos and Poshyvanyk, Denys},
title = {Revisiting Android Reuse Studies in the Context of Code Obfuscation and Library Usages},
year = {2014},
isbn = {9781450328630},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/2597073.2597109},
doi = {10.1145/2597073.2597109},
abstract = { In the recent years, studies of design and programming practices in mobile development are gaining more attention from researchers. Several such empirical studies used Android applications (paid, free, and open source) to analyze factors such as size, quality, dependencies, reuse, and cloning. Most of the studies use executable files of the apps (APK files), instead of source code because of availability issues (most of free apps available at the Android official market are not open-source, but still can be downloaded and analyzed in APK format). However, using only APK files in empirical studies comes with some threats to the validity of the results. In this paper, we analyze some of these pertinent threats. In particular, we analyzed the impact of third-party libraries and code obfuscation practices on estimating the amount of reuse by class cloning in Android apps. When including and excluding third-party libraries from the analysis, we found statistically significant differences in the amount of class cloning 24,379 free Android apps. Also, we found some evidence that obfuscation is responsible for increasing a number of false positives when detecting class clones. Finally, based on our findings, we provide a list of actionable guidelines for mining and analyzing large repositories of Android applications and minimizing these threats to validity },
booktitle = {Proceedings of the 11th Working Conference on Mining Software Repositories},
pages = {242–251},
numpages = {10},
keywords = {reuse, Android, third-party libraries, class cloning, obfuscated code},
location = {Hyderabad, India},
series = {MSR 2014}
}

@inproceedings{10.1109/ESEM.2017.45,
author = {Malloy, Brian A. and Power, James F.},
title = {Quantifying the Transition from Python 2 to 3: An Empirical Study of Python Applications},
year = {2017},
isbn = {9781509040391},
publisher = {IEEE Press},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1109/ESEM.2017.45},
doi = {10.1109/ESEM.2017.45},
abstract = {Background: Python is one of the most popular modern programming languages. In 2008 its authors introduced a new version of the language, Python 3.0, that was not backward compatible with Python 2, initiating a transitional phase for Python software developers. Aims: The study described in this paper investigates the degree to which Python software developers are making the transition from Python 2 to Python 3. Method: We have developed a Python compliance analyser, PyComply, and have assembled a large corpus of Python applications. We use PyComply to measure and quantify the degree to which Python 3 features are being used, as well as the rate and context of their adoption. Results: In fact, Python software developers are not exploiting the new features and advantages of Python 3, but rather are choosing to retain backward compatibility with Python 2. Conclusions: Python developers are confining themselves to a language subset, governed by the diminishing intersection of Python 2, which is not under development, and Python 3, which is under development with new features being introduced as the language continues to evolve.},
booktitle = {Proceedings of the 11th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
pages = {314–323},
numpages = {10},
location = {Markham, Ontario, Canada},
series = {ESEM '17}
}

@inproceedings{10.1145/3387906.3388629,
author = {Sundelin, Anders and Gonzalez-Huerta, Javier and Wnuk, Krzysztof},
title = {The Hidden Cost of Backward Compatibility: When Deprecation Turns into Technical Debt - an Experience Report},
year = {2020},
isbn = {9781450379601},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/3387906.3388629},
doi = {10.1145/3387906.3388629},
abstract = {Context The micro-services architectural pattern advocates for the partitioning of functionality into loosely coupled services, which should be backward compatible, to enable independent upgrades. Deprecation is commonly used as a tool to manage multiple versions of methods or services. However, deprecation carries a cost in that tests might be duplicated and might rely on services that have become deprecated over time.Objective Using the terms of the Technical Debt metaphor, we explore the consequences of deprecation, and how it has affected the test base during seven years.Method We take an exploratory approach, reporting on experiences found before and after servicing parts of the incurred Technical Debt. We mine code repositories and validate our findings with experienced developers.Results We found that the growth of deprecation debt varied a lot. Some services experienced substantial growth, but most did not. Unit tests, where deprecation is visible in the developers' tools, were much less affected than integration tests, which lack such visualization mechanisms. While servicing debt of 121 out of 285 deprecated services, we discovered that up to 29% of the spent effort could be attributed to accrued interest. However, this is an upper bound; there could be less impact, depending on whether scripting could be used to service the debt or not.Conclusion This paper illustrates that integration tests can be viewed as a debt from the perspective of deprecated services. While the pattern was that deprecated services (debt principal) experienced no or little accrued interest, some, highly used, services experienced a lot, particularly during stressful times. Java-based tests, where deprecation is visible in the IDE, did not experience a similar pattern of increasing debt. We postulate that deprecation debt should be kept visible, either using developer tools or statistical reports.},
booktitle = {Proceedings of the 3rd International Conference on Technical Debt},
pages = {67–76},
numpages = {10},
keywords = {backwards compatibility, deprecation, automated test base, technical debt},
location = {Seoul, Republic of Korea},
series = {TechDebt '20}
}

@inproceedings{10.1145/2597008.2597155,
author = {Linares-V\'{a}squez, Mario and Bavota, Gabriele and Di Penta, Massimiliano and Oliveto, Rocco and Poshyvanyk, Denys},
title = {How Do API Changes Trigger Stack Overflow Discussions? A Study on the Android SDK},
year = {2014},
isbn = {9781450328791},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/2597008.2597155},
doi = {10.1145/2597008.2597155},
abstract = { The growing number of questions related to mobile development in StackOverflow highlights an increasing interest of software developers in mobile programming. For the Android platform, 213,836 questions were tagged with Android-related labels in StackOverflow between July 2008 and August 2012. This paper aims at investigating how changes occurring to Android APIs trigger questions and activity in StackOverflow, and whether this is particularly true for certain kinds of changes. Our findings suggest that Android developers usually have more questions when the behavior of APIs is modified. In addition, deleting public methods from APIs is a trigger for questions that are (i) more discussed and of major interest for the community, and (ii) posted by more experienced developers. In general, results of this paper provide important insights about the use of social media to learn about changes in software ecosystems, and establish solid foundations for building new recommenders for notifying developers/managers about important changes and recommending them relevant crowdsourced solutions },
booktitle = {Proceedings of the 22nd International Conference on Program Comprehension},
pages = {83–94},
numpages = {12},
keywords = {StackOverflow, Android, API changes, Social media},
location = {Hyderabad, India},
series = {ICPC 2014}
}

@inproceedings{10.1145/1368088.1368154,
author = {Dagenais, Barth\'{e}l\'{e}my and Robillard, Martin P.},
title = {Recommending Adaptive Changes for Framework Evolution},
year = {2008},
isbn = {9781605580791},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/1368088.1368154},
doi = {10.1145/1368088.1368154},
abstract = {In the course of a framework's evolution, changes ranging from a simple refactoring to a complete rearchitecture can break client programs. Finding suitable replacements for framework elements that were accessed by a client program and deleted as part of the framework's evolution can be a challenging task. We present a recommendation system, SemDiff, that suggests adaptations to client programs by analyzing how a framework adapts to its own changes. In a study of the evolution of the Eclipse JDT framework and three client programs, our approach recommended relevant adaptive changes with a high level of precision, and detected non-trivial changes typically undiscovered by current refactoring detection techniques.},
booktitle = {Proceedings of the 30th International Conference on Software Engineering},
pages = {481–490},
numpages = {10},
keywords = {mining software repositories, software evolution, adaptive changes, partial program analysis, origin analysis, historical study, recommendation system, framework},
location = {Leipzig, Germany},
series = {ICSE '08}
}

@inproceedings{10.1145/3377811.3380362,
author = {Zhang, Ru and Xiao, Wencong and Zhang, Hongyu and Liu, Yu and Lin, Haoxiang and Yang, Mao},
title = {An Empirical Study on Program Failures of Deep Learning Jobs},
year = {2020},
isbn = {9781450371216},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/3377811.3380362},
doi = {10.1145/3377811.3380362},
abstract = {Deep learning has made significant achievements in many application areas. To train and test models more efficiently, enterprise developers submit and run their deep learning programs on a shared, multi-tenant platform. However, some of the programs fail after a long execution time due to code/script defects, which reduces the development productivity and wastes expensive resources such as GPU, storage, and network I/O.This paper presents the first comprehensive empirical study on program failures of deep learning jobs. 4960 real failures are collected from a deep learning platform in Microsoft. We manually examine their failure messages and classify them into 20 categories. In addition, we identify the common root causes and bug-fix solutions on a sample of 400 failures. To better understand the current testing and debugging practices for deep learning, we also conduct developer interviews. Our major findings include: (1) 48.0% of the failures occur in the interaction with the platform rather than in the execution of code logic, mostly due to the discrepancies between local and platform execution environments; (2) Deep learning specific failures (13.5%) are mainly caused by inappropriate model parameters/structures and framework API misunderstanding; (3) Current debugging practices are not efficient for fault localization in many cases, and developers need more deep learning specific tools. Based on our findings, we further suggest possible research topics and tooling support that could facilitate future deep learning development.},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering},
pages = {1159–1170},
numpages = {12},
keywords = {program failures, empirical study, deep learning jobs},
location = {Seoul, South Korea},
series = {ICSE '20}
}

@inproceedings{10.1109/ICSE.2019.00094,
author = {Wei, Lili and Liu, Yepang and Cheung, Shing-Chi},
title = {Pivot: Learning API-Device Correlations to Facilitate Android Compatibility Issue Detection},
year = {2019},
publisher = {IEEE Press},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1109/ICSE.2019.00094},
doi = {10.1109/ICSE.2019.00094},
abstract = {The heavily fragmented Android ecosystem has induced various compatibility issues in Android apps. The search space for such fragmentation-induced compatibility issues (FIC issues) is huge, comprising three dimensions: device models, Android OS versions, and Android APIs. FIC issues, especially those arising from device models, evolve quickly with the frequent release of new device models to the market. As a result, an automated technique is desired to maintain timely knowledge of such FIC issues, which are mostly undocumented. In this paper, we propose such a technique, PIVOT, that automatically learns API-device correlations of FIC issues from existing Android apps. PIVOT extracts and prioritizes API-device correlations from a given corpus of Android apps. We evaluated PIVOT with popular Android apps on Google Play. Evaluation results show that PIVOT can effectively prioritize valid API-device correlations for app corpora collected at different time. Leveraging the knowledge in the learned API-device correlations, we further conducted a case study and successfully uncovered ten previously-undetected FIC issues in open-source Android apps.},
booktitle = {Proceedings of the 41st International Conference on Software Engineering},
pages = {878–888},
numpages = {11},
keywords = {compatibility, Android fragmentation, static analysis, learning},
location = {Montreal, Quebec, Canada},
series = {ICSE '19}
}

@inproceedings{10.1145/3238147.3238188,
author = {Liu, Jie and Wu, Diyu and Xue, Jingling},
title = {TDroid: Exposing App Switching Attacks in Android with Control Flow Specialization},
year = {2018},
isbn = {9781450359375},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/3238147.3238188},
doi = {10.1145/3238147.3238188},
abstract = {The Android multitasking mechanism can be plagued with app switching attacks, in which a malicious app replaces the legitimate top activity of the focused app with one of its own, thus mounting, e.g., phishing and denial-of-service attacks. Existing market-level defenses are still ineffective, as static analysis is fundamentally unable to reason about the intention of an app and dynamic analysis has low coverage. We introduce TDroid, a new market-level approach to detecting app switching attacks. The challenge lies in how to handle a plethora of input-dependent branch predicates (forming an exponential number of paths) that control the execution of the code responsible for launching such attacks. TDroid tackles this challenge by combining static and dynamic analysis to analyze an app without producing any false positives. In its static analysis, TDroid transforms the app into runnable slices containing potentially app switching attacks, one slice per attack. In its dynamic analysis, TDroid executes these slices on an Android phone or emulator to expose their malicious GUIs. The novelty lies in the use of a new trigger-oriented slicing technique in producing runnable slices so that certain input-dependent branch predicates are specialized to execute always some fixed branches. Evaluated with a large set of malware apps, TDroid is shown to outperform the state of the art, by detecting substantially more app switching attacks, in a few minutes per app, on average.},
booktitle = {Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering},
pages = {236–247},
numpages = {12},
keywords = {Android GUI Security, Dynamic Analysis, Static Analysis},
location = {Montpellier, France},
series = {ASE 2018}
}

@article{10.1145/583960.583964,
author = {Varela, Carlos and Agha, Gul},
title = {Programming Dynamically Reconfigurable Open Systems with SALSA},
year = {2001},
issue_date = {December 2001},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {36},
number = {12},
issn = {0362-1340},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/583960.583964},
doi = {10.1145/583960.583964},
abstract = {Applications running on the Internet, or on limited-resource devices, need to be able to adapt to changes in their execution environment at run-time. Current languages and systems fall short of enabling developers to migrate and reconfigure application sub-components at program-execution time.In this paper, we describe essential aspects of the design and implementation of SALSA, an actor-based language for mobile and Internet computing. SALSA simplifies programming dynamically reconfigurable, open applications by providing universal names, active objects, and migration. Moreover, SALSA introduces three language mechanisms to help programmers coordinate asynchronous, mobile computations: token-passing continuations, join continuations and first-class continuations.We provide some examples which illustrate how SALSA programs are not only dynamically reconfigurable and open, but also much more concise and easier to follow than comparable Java code. Furthermore, we provide empirical results which show SALSA's performance to be better than Java code using an actor library, and which illustrate the difference between local, local area, and wide area communication and migration. Finally, we discuss the implementation of our preprocessor which translates SALSA code into Java.},
journal = {SIGPLAN Not.},
month = dec,
pages = {20–34},
numpages = {15},
keywords = {open systems, internet, java, actors, continuations, SALSA, mobile computing, programming languages, network computing}
}

@inproceedings{10.1145/1869459.1869518,
author = {Kapur, Puneet and Cossette, Brad and Walker, Robert J.},
title = {Refactoring References for Library Migration},
year = {2010},
isbn = {9781450302036},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/1869459.1869518},
doi = {10.1145/1869459.1869518},
abstract = {Automated refactoring is a key feature of modern IDEs. Existing refactorings rely on the transformation of source code declarations, in which references may also be transformed as a side effect. However, there exist situations in which a declaration is not available for refactoring or would be inappropriate to transform, for example, in the presence of dangling references or where a set of references should be retargeted to a different declaration.We investigate the problem of dangling references through a detailed study of three open source libraries. We find that the introduction of dangling references during library migration is a significant real problem, and characterize the specific issues that arise. Based on these findings we provide and test a prototype tool, called Trident, that allows programmers to refactor references. Our results suggest that supporting the direct refactoring of references is a significant improvement over the state-of-the-art.},
booktitle = {Proceedings of the ACM International Conference on Object Oriented Programming Systems Languages and Applications},
pages = {726–738},
numpages = {13},
keywords = {flexible transformation, trident, flexible search, refactoring, library migration, dangling references},
location = {Reno/Tahoe, Nevada, USA},
series = {OOPSLA '10}
}

@article{10.1145/1932682.1869518,
author = {Kapur, Puneet and Cossette, Brad and Walker, Robert J.},
title = {Refactoring References for Library Migration},
year = {2010},
issue_date = {October 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {45},
number = {10},
issn = {0362-1340},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/1932682.1869518},
doi = {10.1145/1932682.1869518},
abstract = {Automated refactoring is a key feature of modern IDEs. Existing refactorings rely on the transformation of source code declarations, in which references may also be transformed as a side effect. However, there exist situations in which a declaration is not available for refactoring or would be inappropriate to transform, for example, in the presence of dangling references or where a set of references should be retargeted to a different declaration.We investigate the problem of dangling references through a detailed study of three open source libraries. We find that the introduction of dangling references during library migration is a significant real problem, and characterize the specific issues that arise. Based on these findings we provide and test a prototype tool, called Trident, that allows programmers to refactor references. Our results suggest that supporting the direct refactoring of references is a significant improvement over the state-of-the-art.},
journal = {SIGPLAN Not.},
month = oct,
pages = {726–738},
numpages = {13},
keywords = {trident, dangling references, flexible transformation, library migration, refactoring, flexible search}
}

@inproceedings{10.1145/3313831.3376382,
author = {Zhang, Tianyi and Hartmann, Bj\"{o}rn and Kim, Miryung and Glassman, Elena L.},
title = {Enabling Data-Driven API Design with Community Usage Data: A Need-Finding Study},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/3313831.3376382},
doi = {10.1145/3313831.3376382},
abstract = {APIs are becoming the fundamental building block of modern software and their usability is crucial to programming efficiency and software quality. Yet API designers find it hard to gather and interpret user feedback on their APIs. To close the gap, we interviewed 23 API designers from 6 companies and 11 open-source projects to understand their practices and needs. The primary way of gathering user feedback is through bug reports and peer reviews, as formal usability testing is prohibitively expensive to conduct in practice. Participants expressed a strong desire to gather real-world use cases and understand users' mental models, but there was a lack of tool support for such needs. In particular, participants were curious about where users got stuck, their workarounds, common mistakes, and unanticipated corner cases. We highlight several opportunities to address those unmet needs, including developing new mechanisms that systematically elicit users' mental models, building mining frameworks that identify recurring patterns beyond shallow statistics about API usage, and exploring alternative design choices made in similar libraries.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {tool support, community, information needs, api design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3238147.3238180,
author = {Hu, Jiajun and Wei, Lili and Liu, Yepang and Cheung, Shing-Chi and Huang, Huaxun},
title = {A Tale of Two Cities: How WebView Induces Bugs to Android Applications},
year = {2018},
isbn = {9781450359375},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/3238147.3238180},
doi = {10.1145/3238147.3238180},
abstract = {WebView is a widely used Android component that augments a native app with web browser capabilities. It eases the interactions between an app’s native code and web code. However, the interaction mechanism of WebView induces new types of bugs in Android apps. Understanding the characteristics and manifestation of these WebView-induced bugs (ωBugs for short) facilitates the correct usages of WebViews in Android apps. This motivates us to conduct the first empirical study on ωBugs based on those found in popular open-source Android apps. Our study identified the major root causes and consequences of ωBugs and made interesting observations that can be leveraged for detecting and diagnosing ωBugs. Based on the empirical study, we further propose an automated testing technique ωDroid to effectively expose ωBugs in Android apps. In our experiments, ωDroid successfully discovered 30 unique and previously-unknown ωBugs when applied to 146 open-source Android apps. We reported the 30 ωBugs to the corresponding app developers. Out of these 30 ωBugs, 14 were confirmed and 7 of them were fixed. This shows that ωDroid can effectively detect ωBugs that are of the developers’ concern.},
booktitle = {Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering},
pages = {702–713},
numpages = {12},
keywords = {Android system WebView, Empirical study, GUI testing},
location = {Montpellier, France},
series = {ASE 2018}
}

@inproceedings{10.1109/MSR.2019.00055,
author = {Scalabrino, Simone and Bavota, Gabriele and Linares-V\'{a}squez, Mario and Lanza, Michele and Oliveto, Rocco},
title = {Data-Driven Solutions to Detect API Compatibility Issues in Android: An Empirical Study},
year = {2019},
publisher = {IEEE Press},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1109/MSR.2019.00055},
doi = {10.1109/MSR.2019.00055},
abstract = {Android apps are inextricably linked to the official Android APIs. Such a strong form of dependency implies that changes introduced in new versions of the Android APIs can severely impact the apps' code, for example because of deprecated or removed APIs. In reaction to those changes, mobile app developers are expected to adapt their code and avoid compatibility issues. To support developers, approaches have been proposed to automatically identify API compatibility issues in Android apps. The state-of-the-art approach, named CiD, is a data-driven solution learning how to detect those issues by analyzing the changes in the history of Android APIs ("API side" learning). While it can successfully identify compatibility issues, it cannot recommend coding solutions.We devised an alternative data-driven approach, named ACRyL. ACRyL learns from changes implemented in other apps in response to API changes ("client side" learning). This allows not only to detect compatibility issues, but also to suggest a fix. When empirically comparing the two tools, we found that there is no clear winner, since the two approaches are highly complementary, in that they identify almost disjointed sets of API compatibility issues. Our results point to the future possibility of combining the two approaches, trying to learn detection/fixing rules on both the API and the client side.},
booktitle = {Proceedings of the 16th International Conference on Mining Software Repositories},
pages = {288–298},
numpages = {11},
keywords = {Android, API compatibility issues, empirical study},
location = {Montreal, Quebec, Canada},
series = {MSR '19}
}

@inproceedings{10.1145/3238147.3238219,
author = {Huang, Kaifeng and Chen, Bihuan and Peng, Xin and Zhou, Daihong and Wang, Ying and Liu, Yang and Zhao, Wenyun},
title = {ClDiff: Generating Concise Linked Code Differences},
year = {2018},
isbn = {9781450359375},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/3238147.3238219},
doi = {10.1145/3238147.3238219},
abstract = {Analyzing and understanding source code changes is important in a variety of software maintenance tasks. To this end, many code differencing and code change summarization methods have been proposed. For some tasks (e.g. code review and software merging), however, those differencing methods generate too fine-grained a representation of code changes, and those summarization methods generate too coarse-grained a representation of code changes. Moreover, they do not consider the relationships among code changes. Therefore, the generated differences or summaries make it not easy to analyze and understand code changes in some software maintenance tasks.  In this paper, we propose a code differencing approach, named CLDIFF, to generate concise linked code differences whose granularity is in between the existing code differencing and code change summarization methods. The goal of CLDIFF is to generate more easily understandable code differences. CLDIFF takes source code files before and after changes as inputs, and consists of three steps. First, it pre-processes the source code files by pruning unchanged declara- tions from the parsed abstract syntax trees. Second, it generates concise code differences by grouping fine-grained code differences at or above the statement level and describing high-level changes in each group. Third, it links the related concise code differences according to five pre-defined links. Experiments with 12 Java projects (74,387 commits) and a human study with 10 participants have indicated the accuracy, conciseness, performance and usefulness of CLDIFF.},
booktitle = {Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering},
pages = {679–690},
numpages = {12},
keywords = {Code Differencing, Program Comprehension, AST},
location = {Montpellier, France},
series = {ASE 2018}
}

@inproceedings{10.1109/ICSE.2017.42,
author = {Ma, Wanwangying and Chen, Lin and Zhang, Xiangyu and Zhou, Yuming and Xu, Baowen},
title = {How Do Developers Fix Cross-Project Correlated Bugs? A Case Study on the GitHub Scientific Python Ecosystem},
year = {2017},
isbn = {9781538638682},
publisher = {IEEE Press},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1109/ICSE.2017.42},
doi = {10.1109/ICSE.2017.42},
abstract = {GitHub, a popular social-software-development platform, has fostered a variety of software ecosystems where projects depend on one another and practitioners interact with each other. Projects within an ecosystem often have complex inter-dependencies that impose new challenges in bug reporting and fixing. In this paper, we conduct an empirical study on cross-project correlated bugs, i.e., causally related bugs reported to different projects, focusing on two aspects: 1) how developers track the root causes across projects; and 2) how the downstream developers coordinate to deal with upstream bugs. Through manual inspection of bug reports collected from the scientific Python ecosystem and an online survey with developers, this study reveals the common practices of developers and the various factors in fixing cross-project bugs. These findings provide implications for future software bug analysis in the scope of ecosystem, as well as shed light on the requirements of issue trackers for such bugs.},
booktitle = {Proceedings of the 39th International Conference on Software Engineering},
pages = {381–392},
numpages = {12},
keywords = {coordinate, cross-project correlated bugs, GitHub ecosystems, root causes tracking},
location = {Buenos Aires, Argentina},
series = {ICSE '17}
}

@inproceedings{10.1145/2600821.2600829,
author = {Chen, Jie and Xiao, Junchao and Wang, Qing and Osterweil, Leon J. and Li, Mingshu},
title = {Refactoring Planning and Practice in Agile Software Development: An Empirical Study},
year = {2014},
isbn = {9781450327541},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/2600821.2600829},
doi = {10.1145/2600821.2600829},
abstract = { Agile software engineering increasingly seeks to incorporate design modification and continuous refactoring in order to maintain code quality even in highly dynamic environments. However, there does not currently appear to be an industry-wide consensus on how to do this and research in this area expresses conflicting opinions. This paper presents an empirical study based upon an industry survey aimed at understanding the different ways that refactoring is thought of by the different people carrying out different roles in agile processes and how these different people weigh the importance of refactoring versus other kinds of tasks in the process. The study found good support for the importance of refactoring, but most respondents agreed that deferred refactoring impacts the agility of their process. Thus there was no universally agreed-upon strategy for planning refactoring. The survey findings also indicated that different roles have different perspectives on the different kinds of tasks in an agile process although all seem to want to increase the priority given to refactoring during planning for the iterations in agile development. Analysis of the survey raised many interesting questions suggesting the need for a considerable amount of future research. },
booktitle = {Proceedings of the 2014 International Conference on Software and System Process},
pages = {55–64},
numpages = {10},
keywords = {Iteration Planning, Refactoring, Agile, Project Management},
location = {Nanjing, China},
series = {ICSSP 2014}
}

@inproceedings{10.1145/2393596.2393662,
author = {Robbes, Romain and Lungu, Mircea and R\"{o}thlisberger, David},
title = {How Do Developers React to API Deprecation? The Case of a Smalltalk Ecosystem},
year = {2012},
isbn = {9781450316149},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/2393596.2393662},
doi = {10.1145/2393596.2393662},
abstract = {When the Application Programming Interface (API) of a framework or library changes, its clients must be adapted. This change propagation---known as a ripple effect---is a problem that has garnered interest: several approaches have been proposed in the literature to react to these changes.Although studies of ripple effects exist at the single system level, no study has been performed on the actual extent and impact of these API changes in practice, on an entire software ecosystem associated with a community of developers. This paper reports on an empirical study of API deprecations that led to ripple effects across an entire ecosystem. Our case study subject is the development community gravitating around the Squeak and Pharo software ecosystems: seven years of evolution, more than 3,000 contributors, and more than 2,600 distinct systems. We analyzed 577 methods and 186 classes that were deprecated, and answer research questions regarding the frequency, magnitude, duration, adaptation, and consistency of the ripple effects triggered by API changes.},
booktitle = {Proceedings of the ACM SIGSOFT 20th International Symposium on the Foundations of Software Engineering},
articleno = {56},
numpages = {11},
keywords = {mining software repositories, ecosystems, empirical studies},
location = {Cary, North Carolina},
series = {FSE '12}
}

@inproceedings{10.1145/3377811.3380442,
author = {Ma, Wanwangying and Chen, Lin and Zhang, Xiangyu and Feng, Yang and Xu, Zhaogui and Chen, Zhifei and Zhou, Yuming and Xu, Baowen},
title = {Impact Analysis of Cross-Project Bugs on Software Ecosystems},
year = {2020},
isbn = {9781450371216},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/3377811.3380442},
doi = {10.1145/3377811.3380442},
abstract = {Software projects are increasingly forming social-technical ecosystems within which individual projects rely on the infrastructures or functional components provided by other projects, leading to complex inter-dependencies. Through inter-project dependencies, a bug in an upstream project may have profound impact on a large number of downstream projects, resulting in cross-project bugs. This emerging type of bugs has brought new challenges in bug fixing due to their unclear influence on downstream projects. In this paper, we present an approach to estimating the impact of a cross-project bug within its ecosystem by identifying the affected downstream modules (classes/methods). Note that a downstream project that uses a buggy upstream function may not be affected as the usage does not satisfy the failure inducing preconditions. For a reported bug with the known root cause function and failure inducing preconditions, we first collect the candidate downstream modules that call the upstream function through an ecosystem-wide dependence analysis. Then, the paths to the call sites of the buggy upstream function are encoded as symbolic constraints. Solving the constraints, together with the failure inducing preconditions, identifies the affected downstream modules. Our evaluation of 31 existing upstream bugs on the scientific Python ecosystem containing 121 versions of 22 popular projects (with a total of 16 millions LOC) shows that the approach is highly effective: from the 25490 candidate downstream modules that invoke the buggy upstream functions, it identifies 1132 modules where the upstream bugs can be triggered, pruning 95.6% of the candidates. The technique has no false negatives and an average false positive rate of 7.9%. Only 49 downstream modules (out of the 1132 we found) were reported before to be affected.},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering},
pages = {100–111},
numpages = {12},
keywords = {cross-project bugs, symbolic constraints, software ecosystems, bug impact, dependence analysis},
location = {Seoul, South Korea},
series = {ICSE '20}
}

@article{10.1145/2990497,
author = {Azad, Shams and Rigby, Peter C. and Guerrouj, Latifa},
title = {Generating API Call Rules from Version History and Stack Overflow Posts},
year = {2017},
issue_date = {May 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {25},
number = {4},
issn = {1049-331X},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/2990497},
doi = {10.1145/2990497},
abstract = {Researchers have shown that related functions can be mined from groupings of functions found in the version history of a system. Our first contribution is to expand this approach to a community of applications and set of similar applications. Android developers use a set of application programming interface (API) calls when creating apps. These API calls are used in similar ways across multiple applications. By clustering co-changing API calls used by 230 Android apps across 12k versions, we are able to predict the API calls that individual app developers will use with an average precision of 75% and recall of 22%. When we make predictions from the same category of app, such as Finance, we attain precision and recall of 81% and 28%, respectively.Our second contribution can be characterized as “programmers who discussed these functions were also interested in these functions.” Informal discussions on Stack Overflow provide a rich source of information about related API calls as developers provide solutions to common problems. By grouping API calls contained in each positively voted answer posts, we are able to create rules that predict the calls that app developers will use in their own apps with an average precision of 66% and recall of 13%.For comparison purposes, we developed a baseline by clustering co-changing API calls for each individual app and generated association rules from them. The baseline predicts API calls used by app developers with a precision and recall of 36% and 23%, respectively.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = jan,
articleno = {29},
numpages = {22},
keywords = {version history, informal documentation, community of applications, association rule mining, Stack Overflow, API method calls}
}

@inproceedings{10.1145/2678015.2682534,
author = {Li, Jun and Wang, Chenglong and Xiong, Yingfei and Hu, Zhenjiang},
title = {SWIN: Towards Type-Safe Java Program Adaptation between APIs},
year = {2015},
isbn = {9781450332972},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/2678015.2682534},
doi = {10.1145/2678015.2682534},
abstract = {Java program adaptation between different APIs is a common task in software development. When an old API is upgraded to an incompatible new version, or when we want to migrate an application from one platform to another platform, we need to adapt programs between different APIs. Although different program transformation tools have been developed to automate the program adaptation task, no tool ensures type safety in transforming Java programs: given a transformation program and any well-typed Java program, the transformed result is still well-typed. As a matter of fact, it is often observed that a dedicated adaptation tool turns a working application into a set of incompatible programs. We address this problem by providing a type-safe transformation language, SWIN, for Java program adaptation between different APIs. SWIN is based on Twinning, a modern transformation language for Java programs. SWIN enhances Twinning with more flexible transformation rules, formal semantics, and, most importantly, full type-safe guarantee. We formally prove the type safety of SWIN on Featherweight Java, a known minimal formal core of Java. Our experience with three case studies shows that SWIN is as expressive as Twinning in specifying useful program transformations in the case studies while guaranteeing the type safety of the transformations.},
booktitle = {Proceedings of the 2015 Workshop on Partial Evaluation and Program Manipulation},
pages = {91–102},
numpages = {12},
keywords = {transformation language, type safety, program transformation, api adaptation},
location = {Mumbai, India},
series = {PEPM '15}
}

@inproceedings{10.1145/3342195.3387530,
author = {Gong, Liangyi and Li, Zhenhua and Qian, Feng and Zhang, Zifan and Chen, Qi Alfred and Qian, Zhiyun and Lin, Hao and Liu, Yunhao},
title = {Experiences of Landing Machine Learning onto Market-Scale Mobile Malware Detection},
year = {2020},
isbn = {9781450368827},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/3342195.3387530},
doi = {10.1145/3342195.3387530},
abstract = {App markets, being crucial and critical for today's mobile ecosystem, have also become a natural malware delivery channel since they actually "lend credibility" to malicious apps. In the past decade, machine learning (ML) techniques have been explored for automated, robust malware detection. Unfortunately, to date, we have yet to see an ML-based malware detection solution deployed at market scales. To better understand the real-world challenges, we conduct a collaborative study with a major Android app market (T-Market) offering us large-scale ground-truth data. Our study shows that the key to successfully developing such systems is manifold, including feature selection/engineering, app analysis speed, developer engagement, and model evolution. Failure in any of the above aspects would lead to the "wooden barrel effect" of the entire system. We discuss our careful design choices as well as our first-hand deployment experiences in building such an ML-powered malware detection system. We implement our design and examine its effectiveness in the T-Market for over one year, using a single commodity server to vet ~ 10K apps every day. The evaluation results show that this design achieves an overall precision of 98% and recall of 96% with an average per-app scan time of 1.3 minutes.},
booktitle = {Proceedings of the Fifteenth European Conference on Computer Systems},
articleno = {2},
numpages = {14},
location = {Heraklion, Greece},
series = {EuroSys '20}
}

@inbook{10.1145/3368089.3409725,
author = {Ketkar, Ameya and Tsantalis, Nikolaos and Dig, Danny},
title = {Understanding Type Changes in Java},
year = {2020},
isbn = {9781450370431},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/3368089.3409725},
abstract = {Developers frequently change the type of a program element and update all its references for performance, security, concurrency,library migration, or better maintainability. Despite type changes being a common program transformation, it is the least automated and the least studied. With this knowledge gap, researchers miss opportunities to improve the state of the art in automation for software evolution, tool builders do not invest resources where automation is most needed, language and library designers can-not make informed decisions when introducing new types, and developers fail to use common practices when changing types. To fill this gap, we present the first large-scale and most fine-grained empirical study on type changes in Java. We develop state-of-the-art tools to statically mine 297,543 type changes and their subsequent code adaptations from a diverse corpus of 129 Java projects containing 416,652 commits. With this rich data set we answer research questions about the practice of type changes. Among others, we found that type changes are actually more common than renaming,but the current research and tools for type changes are inadequate.Based on our extensive and reliable data, we present actionable,empirically-justified implications.},
booktitle = {Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {629–641},
numpages = {13}
}

@inproceedings{10.1145/1542476.1542516,
author = {Ravitch, Tristan and Jackson, Steve and Aderhold, Eric and Liblit, Ben},
title = {Automatic Generation of Library Bindings Using Static Analysis},
year = {2009},
isbn = {9781605583921},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/1542476.1542516},
doi = {10.1145/1542476.1542516},
abstract = {High-level languages are growing in popularity. However, decades of C software development have produced large libraries of fast, time-tested, meritorious code that are impractical to recreate from scratch. Cross-language bindings can expose low-level C code to high-level languages. Unfortunately, writing bindings by hand is tedious and error-prone, while mainstream binding generators require extensive manual annotation or fail to offer the language features that users of modern languages have come to expect.We present an improved binding-generation strategy based on static analysis of unannotated library source code. We characterize three high-level idioms that are not uniquely expressible in C's low-level type system: array parameters, resource managers, and multiple return values. We describe a suite of interprocedural analyses that recover this high-level information, and we show how the results can be used in a binding generator for the Python programming language. In experiments with four large C libraries, we find that our approach avoids the mistakes characteristic of hand-written bindings while offering a level of Python integration unmatched by prior automated approaches. Among the thousands of functions in the public interfaces of these libraries, roughly 40% exhibit the behaviors detected by our static analyses.},
booktitle = {Proceedings of the 30th ACM SIGPLAN Conference on Programming Language Design and Implementation},
pages = {352–362},
numpages = {11},
keywords = {multi-language code reuse, dataflow analysis, ffi, static library analysis, foreign function interfaces, bindings},
location = {Dublin, Ireland},
series = {PLDI '09}
}

@article{10.1145/1543135.1542516,
author = {Ravitch, Tristan and Jackson, Steve and Aderhold, Eric and Liblit, Ben},
title = {Automatic Generation of Library Bindings Using Static Analysis},
year = {2009},
issue_date = {June 2009},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {6},
issn = {0362-1340},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/1543135.1542516},
doi = {10.1145/1543135.1542516},
abstract = {High-level languages are growing in popularity. However, decades of C software development have produced large libraries of fast, time-tested, meritorious code that are impractical to recreate from scratch. Cross-language bindings can expose low-level C code to high-level languages. Unfortunately, writing bindings by hand is tedious and error-prone, while mainstream binding generators require extensive manual annotation or fail to offer the language features that users of modern languages have come to expect.We present an improved binding-generation strategy based on static analysis of unannotated library source code. We characterize three high-level idioms that are not uniquely expressible in C's low-level type system: array parameters, resource managers, and multiple return values. We describe a suite of interprocedural analyses that recover this high-level information, and we show how the results can be used in a binding generator for the Python programming language. In experiments with four large C libraries, we find that our approach avoids the mistakes characteristic of hand-written bindings while offering a level of Python integration unmatched by prior automated approaches. Among the thousands of functions in the public interfaces of these libraries, roughly 40% exhibit the behaviors detected by our static analyses.},
journal = {SIGPLAN Not.},
month = jun,
pages = {352–362},
numpages = {11},
keywords = {static library analysis, bindings, foreign function interfaces, dataflow analysis, ffi, multi-language code reuse}
}

@inproceedings{10.1145/3092703.3092721,
author = {Mostafa, Shaikh and Rodriguez, Rodney and Wang, Xiaoyin},
title = {Experience Paper: A Study on Behavioral Backward Incompatibilities of Java Software Libraries},
year = {2017},
isbn = {9781450350761},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/3092703.3092721},
doi = {10.1145/3092703.3092721},
abstract = { Nowadays, due to the frequent technological innovation and market changes, software libraries are evolving very quickly. Backward compatibility has always been one of the most important requirements during the evolution of software platforms and libraries. However, backward compatibility is seldom fully achieved in practice, and many relevant software failures are reported. Therefore, it is important to understand the status, major reasons, and impact of backward incompatibilities in real world software. This paper presents an empirical study to understand behavioral changes of APIs during evolution of software libraries. Specifically, we performed a large-scale cross-version regression testing on 68 consecutive version pairs from 15 popular Java software libraries. Furthermore, we collected and studied 126 real-world software bugs reports on backward incompatibilities of software libraries. Our major findings include: (1) 1,094 test failures / errors and 296 behavioral backward incompatibilities are detected from 52 of 68 consecutive version pairs; (2) there is a distribution mismatch between incompatibilities detected by library-side regression testing, and bug-inducing incompatibilities; (3) the majority of behavioral backward incompatibilities are not well documented in API documents or release notes; and (4) 67% of fixed client bugs caused by backward incompatibilities in software libraries are fixed by client developers, through several simple change patterns made to the backward incompatible API invocation. },
booktitle = {Proceedings of the 26th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {215–225},
numpages = {11},
keywords = {Library Evolution, Behavioral Backward Incompatibilities},
location = {Santa Barbara, CA, USA},
series = {ISSTA 2017}
}

@inproceedings{10.1145/2950290.2950298,
author = {Zhou, Jing and Walker, Robert J.},
title = {API Deprecation: A Retrospective Analysis and Detection Method for Code Examples on the Web},
year = {2016},
isbn = {9781450342186},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/2950290.2950298},
doi = {10.1145/2950290.2950298},
abstract = { Deprecation allows the developers of application programming interfaces (APIs) to signal to other developers that a given API item ought to be avoided. But little is known about deprecation practices beyond anecdotes. We examine how API deprecation has been used in 26 open source Java frameworks and libraries, finding that the classic deprecate–replace–remove cycle is often not followed, as many APIs were removed without prior deprecation, many deprecated APIs were subsequently un-deprecated, and removed APIs are even resurrected with surprising frequency. Furthermore, we identify several problems in the information commonly (not) provided to help API consumers transition their dependent code.  As a consequence of deprecation, coding examples on the web --- an increasingly important source of information for developers --- can easily become outdated. Code examples that demonstrate how to use deprecated APIs can be difficult to disregard and a waste of time for developers. We propose a lightweight, version-sensitive framework to detect deprecated API usages in source code examples on the web so developers can be informed of such usages before they invest time and energy into studying them. We reify the framework as a prototype tool (Deprecation Watcher). Our evaluation on detecting deprecated Android API usages in code examples on Stack Overflow shows our tool obtains a precision of 100% and a recall of 86% in a random sample of 200 questions. },
booktitle = {Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering},
pages = {266–277},
numpages = {12},
keywords = {deprecation practices, Deprecation Watcher, web-based documentation, API deprecation},
location = {Seattle, WA, USA},
series = {FSE 2016}
}

@inproceedings{10.1145/2384592.2384595,
author = {Afshari, Mehrdad and Barr, Earl T. and Su, Zhendong},
title = {Liberating the Programmer with Prorogued Programming},
year = {2012},
isbn = {9781450315623},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/2384592.2384595},
doi = {10.1145/2384592.2384595},
abstract = {Programming is the process of expressing and refining ideas in a programming language. Ideally, we want our programming language to flexibly fit our natural thought process. Language innovations, such as procedural abstraction, object and aspect orientation, have helped increase programming agility. However, they still lack important features that a programmer could exploit to quickly experiment with design and implementation choices.We propose prorogued programming, a new paradigm more closely aligned with a programmer's thought process. A prorogued programming language (PPL) supports three basic principles: 1) proroguing concerns: the ability to defer a concern, to focus on and finish the current concern; 2) hybrid computation: the ability to involve the programmer as an integral part of computation; and 3) executable refinement: the ability to execute any intermediate program refinements. Working in a PPL, the programmer can run and experiment with an incomplete program, and gradually and iteratively reify the missing parts while catching design and implementation mistakes early. We describe the prorogued programming paradigm, our design and realization of the paradigm using Prorogued C#, our extension to C#, and demonstrate its utility through a few use cases.},
booktitle = {Proceedings of the ACM International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software},
pages = {11–26},
numpages = {16},
keywords = {hybrid computation, prorogued programming, workflow improvement, executable refinement, managing concerns, human computation},
location = {Tucson, Arizona, USA},
series = {Onward! 2012}
}

@article{10.1145/1050849.1057988,
author = {ACM SIGSOFT Software Engineering Notes staff},
title = {Frontmatter (TOC, Letters, Open Source Software (OSS) Patent Search Engine, Calendar of Events, Workshop and Conference Information)},
year = {2005},
issue_date = {March 2005},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {30},
number = {2},
issn = {0163-5948},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/1050849.1057988},
doi = {10.1145/1050849.1057988},
journal = {SIGSOFT Softw. Eng. Notes},
month = mar,
pages = {0},
numpages = {19}
}

@inproceedings{10.1145/2642937.2643010,
author = {Nguyen, Anh Tuan and Nguyen, Hoan Anh and Nguyen, Tung Thanh and Nguyen, Tien N.},
title = {Statistical Learning Approach for Mining API Usage Mappings for Code Migration},
year = {2014},
isbn = {9781450330138},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/2642937.2643010},
doi = {10.1145/2642937.2643010},
abstract = {The same software product nowadays could appear in multiple platforms and devices. To address business needs, software companies develop a software product in a programming language and then migrate it to another one. To support that process, semi-automatic migration tools have been proposed. However, they require users to manually define the mappings between the respective APIs of the libraries used in two languages. To reduce such manual effort, we introduce StaMiner, a novel data-driven approach that statistically learns the mappings between APIs from the corpus of the corresponding client code of the APIs in two languages Java and C#. Instead of using heuristics on the textual or structural similarity between APIs in two languages to map API methods and classes as in existing mining approaches, StaMiner is based on a statistical model that learns the mappings in such a corpus and provides mappings for APIs with all possible arities. Our empirical evaluation on several projects shows that StaMiner can detect API usage mappings with higher accuracy than a state-of-the-art approach. With the resulting API mappings mined by StaMiner, Java2CSharp, an existing migration tool, could achieve a higher level of accuracy.},
booktitle = {Proceedings of the 29th ACM/IEEE International Conference on Automated Software Engineering},
pages = {457–468},
numpages = {12},
keywords = {code migration, api mappings, api usages, statistical learning},
location = {Vasteras, Sweden},
series = {ASE '14}
}

@article{10.1145/3371924,
author = {Cai, Haipeng},
title = {Assessing and Improving Malware Detection Sustainability through App Evolution Studies},
year = {2020},
issue_date = {April 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {29},
number = {2},
issn = {1049-331X},
url = {https://doi-org.proxy.lib.uwaterloo.ca/10.1145/3371924},
doi = {10.1145/3371924},
abstract = {Machine learning–based classification dominates current malware detection approaches for Android. However, due to the evolution of both the Android platform and its user apps, existing such techniques are widely limited by their reliance on new malware samples, which may not be timely available, and constant retraining, which is often very costly. As a result, new and emerging malware slips through, as seen from the continued surging of malware in the wild. Thus, a more practical detector needs not only to be accurate on particular datasets but, more critically, to be able to sustain its capabilities over time without frequent retraining. In this article, we propose and study the sustainability problem for learning-based app classifiers. We define sustainability metrics and compare them among five state-of-the-art malware detectors for Android. We further developed DroidSpan, a novel classification system based on a new behavioral profile for Android apps that captures sensitive access distribution from lightweight profiling. We evaluated the sustainability of DroidSpan versus the five detectors as baselines on longitudinal datasets across the past eight years, which include 13,627 benign apps and 12,755 malware. Through our extensive experiments, we showed that DroidSpan significantly outperformed all the baselines in substainability at reasonable costs, by 6%–32% for same-period detection and 21%–37% for over-time detection. The main takeaway, which also explains the superiority of DroidSpan, is that the use of features consistently differentiating malware from benign apps over time is essential for sustainable learning-based malware detection, and that these features can be learned from studies on app evolution.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = mar,
articleno = {8},
numpages = {28},
keywords = {evolution, malware detection, sustainability, Android apps}
}

@proceedings{10.1145/2950290,
title = {FSE 2016: Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering},
year = {2016},
isbn = {9781450342186},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Seattle, WA, USA}
}

@proceedings{10.1145/2970276,
title = {ASE 2016: Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering},
year = {2016},
isbn = {9781450338455},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Singapore, Singapore}
}

